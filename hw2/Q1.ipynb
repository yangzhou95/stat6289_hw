{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled14.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNtXeVM3W7zC"
      },
      "source": [
        "<h1>Q1</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TBSwgCQLJ6g",
        "outputId": "0f478d91-aa5c-4c60-8e0a-cbb1f9053657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "print(keras.__version__)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ47qU74LUGV",
        "outputId": "c34fcffe-ffd7-4e32-d0df-4ba63cc77384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "data_augmentation = False\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k86yzTulLaOH"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90y10RcaLeaa"
      },
      "source": [
        "def train_cnn(epochs):\n",
        "  if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "  else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "    \n",
        "    # # Save model and weights\n",
        "    # if not os.path.isdir(save_dir):\n",
        "    #     os.makedirs(save_dir)\n",
        "    # model_path = os.path.join(save_dir, model_name)\n",
        "    # model.save(model_path)\n",
        "    # print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "    # Score trained model.\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Accuracy:', scores[1])\n",
        "  return scores[1]\n",
        "    # cnn_performance.append(scores[1])\n",
        "    # print('Test loss:', scores[0])\n",
        "    # print('Test accuracy:', scores[1])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn-MhJnffoDH",
        "outputId": "59d3a37e-12b5-4516-fb95-c53ad2ac32f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cnn_performance =[]\n",
        "for i in range(10):\n",
        "  print(\"validate epoch:{}\".format(i+1))\n",
        "  performance = train_cnn(i+1)\n",
        "  cnn_performance.append(performance)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validate epoch:1\n",
            "Not using data augmentation.\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.8346 - accuracy: 0.3310 - val_loss: 1.5616 - val_accuracy: 0.4448\n",
            "Accuracy: 0.4447999894618988\n",
            "validate epoch:2\n",
            "Not using data augmentation.\n",
            "Epoch 1/2\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4997 - accuracy: 0.4563 - val_loss: 1.3435 - val_accuracy: 0.5290\n",
            "Epoch 2/2\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3485 - accuracy: 0.5218 - val_loss: 1.2297 - val_accuracy: 0.5731\n",
            "Accuracy: 0.5730999708175659\n",
            "validate epoch:3\n",
            "Not using data augmentation.\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2417 - accuracy: 0.5607 - val_loss: 1.1164 - val_accuracy: 0.6119\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1557 - accuracy: 0.5922 - val_loss: 1.1338 - val_accuracy: 0.6095\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0886 - accuracy: 0.6171 - val_loss: 1.0062 - val_accuracy: 0.6458\n",
            "Accuracy: 0.645799994468689\n",
            "validate epoch:4\n",
            "Not using data augmentation.\n",
            "Epoch 1/4\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0278 - accuracy: 0.6387 - val_loss: 0.9837 - val_accuracy: 0.6606\n",
            "Epoch 2/4\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.9839 - accuracy: 0.6542 - val_loss: 0.9356 - val_accuracy: 0.6734\n",
            "Epoch 3/4\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.9458 - accuracy: 0.6712 - val_loss: 0.9072 - val_accuracy: 0.6837\n",
            "Epoch 4/4\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.9159 - accuracy: 0.6791 - val_loss: 0.8611 - val_accuracy: 0.7046\n",
            "Accuracy: 0.7045999765396118\n",
            "validate epoch:5\n",
            "Not using data augmentation.\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8852 - accuracy: 0.6899 - val_loss: 0.8269 - val_accuracy: 0.7127\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8610 - accuracy: 0.7006 - val_loss: 0.8257 - val_accuracy: 0.7144\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8366 - accuracy: 0.7086 - val_loss: 0.8151 - val_accuracy: 0.7158\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8191 - accuracy: 0.7154 - val_loss: 0.8170 - val_accuracy: 0.7209\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8036 - accuracy: 0.7201 - val_loss: 0.7946 - val_accuracy: 0.7250\n",
            "Accuracy: 0.7250000238418579\n",
            "validate epoch:6\n",
            "Not using data augmentation.\n",
            "Epoch 1/6\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7869 - accuracy: 0.7273 - val_loss: 0.7766 - val_accuracy: 0.7300\n",
            "Epoch 2/6\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7714 - accuracy: 0.7325 - val_loss: 0.7957 - val_accuracy: 0.7226\n",
            "Epoch 3/6\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7591 - accuracy: 0.7376 - val_loss: 0.7427 - val_accuracy: 0.7455\n",
            "Epoch 4/6\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7491 - accuracy: 0.7411 - val_loss: 0.7443 - val_accuracy: 0.7455\n",
            "Epoch 5/6\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7353 - accuracy: 0.7467 - val_loss: 0.7678 - val_accuracy: 0.7355\n",
            "Epoch 6/6\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7284 - accuracy: 0.7483 - val_loss: 0.7249 - val_accuracy: 0.7480\n",
            "Accuracy: 0.7480000257492065\n",
            "validate epoch:7\n",
            "Not using data augmentation.\n",
            "Epoch 1/7\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7194 - accuracy: 0.7514 - val_loss: 0.7106 - val_accuracy: 0.7611\n",
            "Epoch 2/7\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7122 - accuracy: 0.7560 - val_loss: 0.7753 - val_accuracy: 0.7386\n",
            "Epoch 3/7\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7086 - accuracy: 0.7591 - val_loss: 0.7603 - val_accuracy: 0.7485\n",
            "Epoch 4/7\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7019 - accuracy: 0.7612 - val_loss: 0.6906 - val_accuracy: 0.7637\n",
            "Epoch 5/7\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6980 - accuracy: 0.7596 - val_loss: 0.6999 - val_accuracy: 0.7587\n",
            "Epoch 6/7\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 0.6890 - accuracy: 0.7658 - val_loss: 0.7346 - val_accuracy: 0.7502\n",
            "Epoch 7/7\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6873 - accuracy: 0.7650 - val_loss: 0.6970 - val_accuracy: 0.7667\n",
            "Accuracy: 0.766700029373169\n",
            "validate epoch:8\n",
            "Not using data augmentation.\n",
            "Epoch 1/8\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6830 - accuracy: 0.7681 - val_loss: 0.7013 - val_accuracy: 0.7640\n",
            "Epoch 2/8\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6805 - accuracy: 0.7696 - val_loss: 0.6981 - val_accuracy: 0.7677\n",
            "Epoch 3/8\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6761 - accuracy: 0.7719 - val_loss: 0.6948 - val_accuracy: 0.7659\n",
            "Epoch 4/8\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6752 - accuracy: 0.7703 - val_loss: 0.7137 - val_accuracy: 0.7612\n",
            "Epoch 5/8\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6728 - accuracy: 0.7749 - val_loss: 0.6964 - val_accuracy: 0.7692\n",
            "Epoch 6/8\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6701 - accuracy: 0.7726 - val_loss: 0.7197 - val_accuracy: 0.7674\n",
            "Epoch 7/8\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6656 - accuracy: 0.7753 - val_loss: 0.7065 - val_accuracy: 0.7647\n",
            "Epoch 8/8\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6644 - accuracy: 0.7759 - val_loss: 0.6767 - val_accuracy: 0.7735\n",
            "Accuracy: 0.7735000252723694\n",
            "validate epoch:9\n",
            "Not using data augmentation.\n",
            "Epoch 1/9\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6623 - accuracy: 0.7763 - val_loss: 0.6802 - val_accuracy: 0.7736\n",
            "Epoch 2/9\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6605 - accuracy: 0.7778 - val_loss: 0.6787 - val_accuracy: 0.7764\n",
            "Epoch 3/9\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6613 - accuracy: 0.7768 - val_loss: 0.6896 - val_accuracy: 0.7701\n",
            "Epoch 4/9\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6635 - accuracy: 0.7769 - val_loss: 0.6770 - val_accuracy: 0.7757\n",
            "Epoch 5/9\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6546 - accuracy: 0.7776 - val_loss: 0.6718 - val_accuracy: 0.7729\n",
            "Epoch 6/9\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6584 - accuracy: 0.7789 - val_loss: 0.6647 - val_accuracy: 0.7817\n",
            "Epoch 7/9\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6524 - accuracy: 0.7813 - val_loss: 0.6704 - val_accuracy: 0.7774\n",
            "Epoch 8/9\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6556 - accuracy: 0.7803 - val_loss: 0.6613 - val_accuracy: 0.7842\n",
            "Epoch 9/9\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6616 - accuracy: 0.7780 - val_loss: 0.6778 - val_accuracy: 0.7802\n",
            "Accuracy: 0.7802000045776367\n",
            "validate epoch:10\n",
            "Not using data augmentation.\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 0.6514 - accuracy: 0.7814 - val_loss: 0.6731 - val_accuracy: 0.7801\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6441 - accuracy: 0.7830 - val_loss: 0.6717 - val_accuracy: 0.7821\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6479 - accuracy: 0.7827 - val_loss: 0.6847 - val_accuracy: 0.7774\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6438 - accuracy: 0.7843 - val_loss: 0.6919 - val_accuracy: 0.7808\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6442 - accuracy: 0.7849 - val_loss: 0.7468 - val_accuracy: 0.7618\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6427 - accuracy: 0.7851 - val_loss: 0.7349 - val_accuracy: 0.7772\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6403 - accuracy: 0.7847 - val_loss: 0.7048 - val_accuracy: 0.7773\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6426 - accuracy: 0.7863 - val_loss: 0.6661 - val_accuracy: 0.7852\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6377 - accuracy: 0.7866 - val_loss: 0.7485 - val_accuracy: 0.7704\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6370 - accuracy: 0.7854 - val_loss: 0.6789 - val_accuracy: 0.7785\n",
            "Accuracy: 0.7785000205039978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMUrCAD4XFKY"
      },
      "source": [
        "<h1>To avoid repeating the training process (time-consuming), I hardcoded the cnn performance by recording the result of a complete training process.</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1el9hZhhDvy"
      },
      "source": [
        "cnn_performance=[]\n",
        "cnn_performance=[0.4327999949455261,\n",
        " 0.5633000135421753,\n",
        " 0.63919997215271,\n",
        " 0.695900022983551,\n",
        " 0.7336999773979187,\n",
        " 0.7494000196456909,\n",
        " 0.7631999850273132,\n",
        " 0.7757999897003174,\n",
        " 0.7749000191688538,\n",
        " 0.7870000004768372]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5amFF3XpoZE",
        "outputId": "f15f792d-e51a-4d3b-f748-503150d271bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "performance_dict = {}\n",
        "performance_dict.update({'cnn':cnn_performance})\n",
        "performance_dict"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cnn': [0.4327999949455261,\n",
              "  0.5633000135421753,\n",
              "  0.63919997215271,\n",
              "  0.695900022983551,\n",
              "  0.7336999773979187,\n",
              "  0.7494000196456909,\n",
              "  0.7631999850273132,\n",
              "  0.7757999897003174,\n",
              "  0.7749000191688538,\n",
              "  0.7870000004768372]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6AJn-fU3zGr",
        "outputId": "656e08e7-6442-40e1-f951-789630923f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "epoch_list = [i+1 for i in range(10)]\n",
        "plt.figure()\n",
        "sns.relplot(x=epoch_list, y=cnn_performance, kind=\"line\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f4530113ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ7eRLhm4uaZ"
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "class TestCallback(Callback):\n",
        "    def __init__(self, test_data):\n",
        "        self.test_data = test_data\n",
        "        self.performance = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        x, y = self.test_data\n",
        "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
        "        self.performance.append(acc)\n",
        "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZeCYyBN5Kha"
      },
      "source": [
        "\n",
        "\n",
        "models =[]\n",
        "nodes =512\n",
        "nodes_per_layer = [512,512,512,512]\n",
        "layers = []\n",
        "batch_size = 64\n",
        "dropout_rate = 0.5\n",
        "num_classes = 10\n",
        "layers = []\n",
        "layers_list = []\n",
        "layers.append(tf.keras.layers.Flatten())\n",
        "for i in range(len(nodes_per_layer)):\n",
        "  layers_list.append(layers)\n",
        "for index in range(len(nodes_per_layer)+1):\n",
        "  if index == 0:\n",
        "    layers.append(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "    models.append(keras.Sequential(layers))\n",
        "    layers = layers[:-1]\n",
        "  else:\n",
        "    layers.append(keras.layers.Dense(nodes, activation=tf.nn.relu)) # Using l2 regularization kernel_regularizer=tf.keras.regularizers.l2(l=0.0001)\n",
        "    layers.append(keras.layers.Dropout(dropout_rate))\n",
        "    layers_list.append(layers)\n",
        "for layers in layers_list:\n",
        "  layers.append(keras.layers.Dense(10, activation='softmax'))\n",
        "  models.append(keras.Sequential(layers)) "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pY0-_AJKwQK",
        "outputId": "ff43a1fc-952d-4847-ff60-6b3de18b1b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqbE9LWb8aeM"
      },
      "source": [
        "\n",
        "def train_dense(model, epochs):\n",
        "  dense_performance = []\n",
        "  overfitting_hist = model.fit(x_train, y_train,epochs=epochs,batch_size=64,validation_data=(x_test,y_test),use_multiprocessing=True)\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "  return scores[1]\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy_UvfxL-0cq",
        "outputId": "ed7c6c5e-8aab-497f-c5f2-c4c0e9c77021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for j in range(len(models)):\n",
        "  models[j].compile(optimizer=opt, \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  dense_performance =[]\n",
        "  for i in range(10):\n",
        "    print(\"validate epoch:{}\".format(i+1))\n",
        "    performance = train_dense(models[j],i+1)\n",
        "    dense_performance.append(performance)\n",
        "  performance_dict.update({\"Dense {}\".format(j):dense_performance})\n",
        "  print(performance_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validate epoch:1\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.0231 - accuracy: 0.2776 - val_loss: 1.9261 - val_accuracy: 0.3133\n",
            "validate epoch:2\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8774 - accuracy: 0.3442 - val_loss: 1.8679 - val_accuracy: 0.3366\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8375 - accuracy: 0.3622 - val_loss: 1.8368 - val_accuracy: 0.3622\n",
            "validate epoch:3\n",
            "Epoch 1/3\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8150 - accuracy: 0.3694 - val_loss: 1.8070 - val_accuracy: 0.3694\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7986 - accuracy: 0.3792 - val_loss: 1.7962 - val_accuracy: 0.3760\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7865 - accuracy: 0.3819 - val_loss: 1.7979 - val_accuracy: 0.3735\n",
            "validate epoch:4\n",
            "Epoch 1/4\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7774 - accuracy: 0.3854 - val_loss: 1.7888 - val_accuracy: 0.3786\n",
            "Epoch 2/4\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7696 - accuracy: 0.3890 - val_loss: 1.7726 - val_accuracy: 0.3815\n",
            "Epoch 3/4\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7622 - accuracy: 0.3915 - val_loss: 1.8098 - val_accuracy: 0.3571\n",
            "Epoch 4/4\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7567 - accuracy: 0.3941 - val_loss: 1.7659 - val_accuracy: 0.3903\n",
            "validate epoch:5\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7519 - accuracy: 0.3959 - val_loss: 1.7744 - val_accuracy: 0.3796\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7465 - accuracy: 0.4006 - val_loss: 1.7622 - val_accuracy: 0.3886\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7429 - accuracy: 0.4006 - val_loss: 1.7686 - val_accuracy: 0.3854\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7388 - accuracy: 0.4022 - val_loss: 1.7530 - val_accuracy: 0.3958\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7356 - accuracy: 0.4007 - val_loss: 1.7592 - val_accuracy: 0.3902\n",
            "validate epoch:6\n",
            "Epoch 1/6\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7321 - accuracy: 0.4045 - val_loss: 1.7634 - val_accuracy: 0.3855\n",
            "Epoch 2/6\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7288 - accuracy: 0.4063 - val_loss: 1.7540 - val_accuracy: 0.3888\n",
            "Epoch 3/6\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7266 - accuracy: 0.4074 - val_loss: 1.7661 - val_accuracy: 0.3779\n",
            "Epoch 4/6\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7231 - accuracy: 0.4078 - val_loss: 1.7600 - val_accuracy: 0.3882\n",
            "Epoch 5/6\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7216 - accuracy: 0.4095 - val_loss: 1.7465 - val_accuracy: 0.3877\n",
            "Epoch 6/6\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7185 - accuracy: 0.4113 - val_loss: 1.7647 - val_accuracy: 0.3816\n",
            "validate epoch:7\n",
            "Epoch 1/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7167 - accuracy: 0.4104 - val_loss: 1.7447 - val_accuracy: 0.3976\n",
            "Epoch 2/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7147 - accuracy: 0.4131 - val_loss: 1.7581 - val_accuracy: 0.3898\n",
            "Epoch 3/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7121 - accuracy: 0.4135 - val_loss: 1.7378 - val_accuracy: 0.3970\n",
            "Epoch 4/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7103 - accuracy: 0.4127 - val_loss: 1.7507 - val_accuracy: 0.3884\n",
            "Epoch 5/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7088 - accuracy: 0.4151 - val_loss: 1.7348 - val_accuracy: 0.3983\n",
            "Epoch 6/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7073 - accuracy: 0.4145 - val_loss: 1.7452 - val_accuracy: 0.3929\n",
            "Epoch 7/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7054 - accuracy: 0.4156 - val_loss: 1.7426 - val_accuracy: 0.3951\n",
            "validate epoch:8\n",
            "Epoch 1/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7043 - accuracy: 0.4182 - val_loss: 1.7504 - val_accuracy: 0.3858\n",
            "Epoch 2/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7024 - accuracy: 0.4171 - val_loss: 1.7598 - val_accuracy: 0.3860\n",
            "Epoch 3/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7012 - accuracy: 0.4179 - val_loss: 1.7348 - val_accuracy: 0.3983\n",
            "Epoch 4/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6998 - accuracy: 0.4184 - val_loss: 1.7404 - val_accuracy: 0.3969\n",
            "Epoch 5/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6982 - accuracy: 0.4210 - val_loss: 1.7429 - val_accuracy: 0.3962\n",
            "Epoch 6/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6977 - accuracy: 0.4187 - val_loss: 1.7363 - val_accuracy: 0.3985\n",
            "Epoch 7/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6953 - accuracy: 0.4211 - val_loss: 1.7298 - val_accuracy: 0.4013\n",
            "Epoch 8/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6942 - accuracy: 0.4189 - val_loss: 1.7418 - val_accuracy: 0.3904\n",
            "validate epoch:9\n",
            "Epoch 1/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6930 - accuracy: 0.4208 - val_loss: 1.7368 - val_accuracy: 0.3956\n",
            "Epoch 2/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6926 - accuracy: 0.4215 - val_loss: 1.7302 - val_accuracy: 0.3986\n",
            "Epoch 3/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6913 - accuracy: 0.4235 - val_loss: 1.7280 - val_accuracy: 0.3997\n",
            "Epoch 4/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6895 - accuracy: 0.4219 - val_loss: 1.7458 - val_accuracy: 0.3934\n",
            "Epoch 5/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6888 - accuracy: 0.4234 - val_loss: 1.7435 - val_accuracy: 0.3928\n",
            "Epoch 6/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6879 - accuracy: 0.4245 - val_loss: 1.7353 - val_accuracy: 0.3982\n",
            "Epoch 7/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6864 - accuracy: 0.4225 - val_loss: 1.7387 - val_accuracy: 0.3946\n",
            "Epoch 8/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6854 - accuracy: 0.4242 - val_loss: 1.7354 - val_accuracy: 0.3970\n",
            "Epoch 9/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6852 - accuracy: 0.4252 - val_loss: 1.7258 - val_accuracy: 0.4011\n",
            "validate epoch:10\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6838 - accuracy: 0.4253 - val_loss: 1.7355 - val_accuracy: 0.3967\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.6829 - accuracy: 0.4249 - val_loss: 1.7457 - val_accuracy: 0.3866\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.6816 - accuracy: 0.4257 - val_loss: 1.7328 - val_accuracy: 0.4011\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6815 - accuracy: 0.4261 - val_loss: 1.7303 - val_accuracy: 0.4023\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6803 - accuracy: 0.4279 - val_loss: 1.7383 - val_accuracy: 0.4001\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6793 - accuracy: 0.4272 - val_loss: 1.7336 - val_accuracy: 0.4010\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6789 - accuracy: 0.4296 - val_loss: 1.7374 - val_accuracy: 0.3947\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6779 - accuracy: 0.4266 - val_loss: 1.7290 - val_accuracy: 0.4010\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6778 - accuracy: 0.4301 - val_loss: 1.7298 - val_accuracy: 0.3964\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6758 - accuracy: 0.4289 - val_loss: 1.7242 - val_accuracy: 0.4016\n",
            "{'cnn': [0.4327999949455261, 0.5633000135421753, 0.63919997215271, 0.695900022983551, 0.7336999773979187, 0.7494000196456909, 0.7631999850273132, 0.7757999897003174, 0.7749000191688538, 0.7870000004768372], 'Dense 0': [0.3133000135421753, 0.362199991941452, 0.3734999895095825, 0.3903000056743622, 0.3901999890804291, 0.3815999925136566, 0.3950999975204468, 0.3903999924659729, 0.4011000096797943, 0.4016000032424927]}\n",
            "validate epoch:1\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.2482 - accuracy: 0.1776 - val_loss: 2.2308 - val_accuracy: 0.1988\n",
            "validate epoch:2\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.2130 - accuracy: 0.2223 - val_loss: 2.2034 - val_accuracy: 0.2278\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.1869 - accuracy: 0.2364 - val_loss: 2.1785 - val_accuracy: 0.2358\n",
            "validate epoch:3\n",
            "Epoch 1/3\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.1628 - accuracy: 0.2502 - val_loss: 2.1587 - val_accuracy: 0.2474\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.1398 - accuracy: 0.2642 - val_loss: 2.1345 - val_accuracy: 0.2562\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.1177 - accuracy: 0.2717 - val_loss: 2.1154 - val_accuracy: 0.2593\n",
            "validate epoch:4\n",
            "Epoch 1/4\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.0971 - accuracy: 0.2765 - val_loss: 2.0954 - val_accuracy: 0.2671\n",
            "Epoch 2/4\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.0775 - accuracy: 0.2800 - val_loss: 2.0775 - val_accuracy: 0.2711\n",
            "Epoch 3/4\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.0588 - accuracy: 0.2808 - val_loss: 2.0600 - val_accuracy: 0.2687\n",
            "Epoch 4/4\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.0413 - accuracy: 0.2833 - val_loss: 2.0448 - val_accuracy: 0.2672\n",
            "validate epoch:5\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.0248 - accuracy: 0.2858 - val_loss: 2.0282 - val_accuracy: 0.2776\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.0091 - accuracy: 0.2897 - val_loss: 2.0177 - val_accuracy: 0.2841\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9944 - accuracy: 0.2954 - val_loss: 1.9991 - val_accuracy: 0.2921\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9801 - accuracy: 0.3056 - val_loss: 1.9880 - val_accuracy: 0.2922\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9673 - accuracy: 0.3079 - val_loss: 1.9742 - val_accuracy: 0.2987\n",
            "validate epoch:6\n",
            "Epoch 1/6\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9547 - accuracy: 0.3102 - val_loss: 1.9628 - val_accuracy: 0.3047\n",
            "Epoch 2/6\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9436 - accuracy: 0.3126 - val_loss: 1.9536 - val_accuracy: 0.3058\n",
            "Epoch 3/6\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9325 - accuracy: 0.3150 - val_loss: 1.9408 - val_accuracy: 0.3082\n",
            "Epoch 4/6\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9225 - accuracy: 0.3178 - val_loss: 1.9317 - val_accuracy: 0.3049\n",
            "Epoch 5/6\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9132 - accuracy: 0.3209 - val_loss: 1.9223 - val_accuracy: 0.3102\n",
            "Epoch 6/6\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9042 - accuracy: 0.3227 - val_loss: 1.9180 - val_accuracy: 0.3068\n",
            "validate epoch:7\n",
            "Epoch 1/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8955 - accuracy: 0.3243 - val_loss: 1.9072 - val_accuracy: 0.3154\n",
            "Epoch 2/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8877 - accuracy: 0.3244 - val_loss: 1.9059 - val_accuracy: 0.3188\n",
            "Epoch 3/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8799 - accuracy: 0.3265 - val_loss: 1.8931 - val_accuracy: 0.3188\n",
            "Epoch 4/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8728 - accuracy: 0.3290 - val_loss: 1.8876 - val_accuracy: 0.3233\n",
            "Epoch 5/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8660 - accuracy: 0.3304 - val_loss: 1.8804 - val_accuracy: 0.3196\n",
            "Epoch 6/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8596 - accuracy: 0.3325 - val_loss: 1.8768 - val_accuracy: 0.3158\n",
            "Epoch 7/7\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8532 - accuracy: 0.3343 - val_loss: 1.8716 - val_accuracy: 0.3174\n",
            "validate epoch:8\n",
            "Epoch 1/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8470 - accuracy: 0.3377 - val_loss: 1.8623 - val_accuracy: 0.3256\n",
            "Epoch 2/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8414 - accuracy: 0.3383 - val_loss: 1.8578 - val_accuracy: 0.3238\n",
            "Epoch 3/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8356 - accuracy: 0.3414 - val_loss: 1.8558 - val_accuracy: 0.3335\n",
            "Epoch 4/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8305 - accuracy: 0.3411 - val_loss: 1.8475 - val_accuracy: 0.3304\n",
            "Epoch 5/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8252 - accuracy: 0.3420 - val_loss: 1.8478 - val_accuracy: 0.3279\n",
            "Epoch 6/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8201 - accuracy: 0.3445 - val_loss: 1.8433 - val_accuracy: 0.3344\n",
            "Epoch 7/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8150 - accuracy: 0.3475 - val_loss: 1.8363 - val_accuracy: 0.3345\n",
            "Epoch 8/8\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8108 - accuracy: 0.3493 - val_loss: 1.8335 - val_accuracy: 0.3350\n",
            "validate epoch:9\n",
            "Epoch 1/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8062 - accuracy: 0.3521 - val_loss: 1.8272 - val_accuracy: 0.3365\n",
            "Epoch 2/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8015 - accuracy: 0.3527 - val_loss: 1.8220 - val_accuracy: 0.3429\n",
            "Epoch 3/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7970 - accuracy: 0.3549 - val_loss: 1.8218 - val_accuracy: 0.3458\n",
            "Epoch 4/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.7932 - accuracy: 0.3567 - val_loss: 1.8214 - val_accuracy: 0.3403\n",
            "Epoch 5/9\n",
            "782/782 [==============================] - 4s 4ms/step - loss: 1.7891 - accuracy: 0.3579 - val_loss: 1.8132 - val_accuracy: 0.3440\n",
            "Epoch 6/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7851 - accuracy: 0.3596 - val_loss: 1.8113 - val_accuracy: 0.3400\n",
            "Epoch 7/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7810 - accuracy: 0.3608 - val_loss: 1.8091 - val_accuracy: 0.3475\n",
            "Epoch 8/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7776 - accuracy: 0.3616 - val_loss: 1.8071 - val_accuracy: 0.3452\n",
            "Epoch 9/9\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7745 - accuracy: 0.3623 - val_loss: 1.8024 - val_accuracy: 0.3511\n",
            "validate epoch:10\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7707 - accuracy: 0.3640 - val_loss: 1.7962 - val_accuracy: 0.3488\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7677 - accuracy: 0.3643 - val_loss: 1.7965 - val_accuracy: 0.3437\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7648 - accuracy: 0.3656 - val_loss: 1.7959 - val_accuracy: 0.3437\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7616 - accuracy: 0.3652 - val_loss: 1.7891 - val_accuracy: 0.3506\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7587 - accuracy: 0.3661 - val_loss: 1.7853 - val_accuracy: 0.3506\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7558 - accuracy: 0.3673 - val_loss: 1.7874 - val_accuracy: 0.3482\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7531 - accuracy: 0.3678 - val_loss: 1.7863 - val_accuracy: 0.3548\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7505 - accuracy: 0.3690 - val_loss: 1.7830 - val_accuracy: 0.3504\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7479 - accuracy: 0.3696 - val_loss: 1.7797 - val_accuracy: 0.3521\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7457 - accuracy: 0.3712 - val_loss: 1.7738 - val_accuracy: 0.3555\n",
            "{'cnn': [0.4327999949455261, 0.5633000135421753, 0.63919997215271, 0.695900022983551, 0.7336999773979187, 0.7494000196456909, 0.7631999850273132, 0.7757999897003174, 0.7749000191688538, 0.7870000004768372], 'Dense 0': [0.3133000135421753, 0.362199991941452, 0.3734999895095825, 0.3903000056743622, 0.3901999890804291, 0.3815999925136566, 0.3950999975204468, 0.3903999924659729, 0.4011000096797943, 0.4016000032424927], 'Dense 1': [0.1987999975681305, 0.23579999804496765, 0.25929999351501465, 0.2671999931335449, 0.2987000048160553, 0.3068000078201294, 0.3174000084400177, 0.33500000834465027, 0.35109999775886536, 0.3555000126361847]}\n",
            "validate epoch:1\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.2647 - accuracy: 0.0992 - val_loss: 2.2458 - val_accuracy: 0.1134\n",
            "validate epoch:2\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.2352 - accuracy: 0.1634 - val_loss: 2.2220 - val_accuracy: 0.1972\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.2107 - accuracy: 0.2027 - val_loss: 2.1987 - val_accuracy: 0.2086\n",
            "validate epoch:3\n",
            "Epoch 1/3\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.1881 - accuracy: 0.2258 - val_loss: 2.1810 - val_accuracy: 0.2336\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.1664 - accuracy: 0.2371 - val_loss: 2.1584 - val_accuracy: 0.2413\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.1456 - accuracy: 0.2449 - val_loss: 2.1389 - val_accuracy: 0.2412\n",
            "validate epoch:4\n",
            "Epoch 1/4\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.1259 - accuracy: 0.2465 - val_loss: 2.1209 - val_accuracy: 0.2423\n",
            "Epoch 2/4\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.1075 - accuracy: 0.2490 - val_loss: 2.1027 - val_accuracy: 0.2444\n",
            "Epoch 3/4\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0902 - accuracy: 0.2478 - val_loss: 2.0874 - val_accuracy: 0.2430\n",
            "Epoch 4/4\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0739 - accuracy: 0.2497 - val_loss: 2.0724 - val_accuracy: 0.2465\n",
            "validate epoch:5\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0590 - accuracy: 0.2528 - val_loss: 2.0598 - val_accuracy: 0.2487\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0451 - accuracy: 0.2605 - val_loss: 2.0478 - val_accuracy: 0.2582\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0323 - accuracy: 0.2706 - val_loss: 2.0343 - val_accuracy: 0.2698\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0203 - accuracy: 0.2746 - val_loss: 2.0292 - val_accuracy: 0.2700\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0097 - accuracy: 0.2759 - val_loss: 2.0175 - val_accuracy: 0.2690\n",
            "validate epoch:6\n",
            "Epoch 1/6\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9995 - accuracy: 0.2784 - val_loss: 2.0060 - val_accuracy: 0.2729\n",
            "Epoch 2/6\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9903 - accuracy: 0.2787 - val_loss: 2.0001 - val_accuracy: 0.2763\n",
            "Epoch 3/6\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9817 - accuracy: 0.2817 - val_loss: 1.9914 - val_accuracy: 0.2736\n",
            "Epoch 4/6\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9737 - accuracy: 0.2813 - val_loss: 1.9872 - val_accuracy: 0.2766\n",
            "Epoch 5/6\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9666 - accuracy: 0.2851 - val_loss: 1.9792 - val_accuracy: 0.2791\n",
            "Epoch 6/6\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9595 - accuracy: 0.2861 - val_loss: 1.9755 - val_accuracy: 0.2825\n",
            "validate epoch:7\n",
            "Epoch 1/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9529 - accuracy: 0.2888 - val_loss: 1.9694 - val_accuracy: 0.2825\n",
            "Epoch 2/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9470 - accuracy: 0.2907 - val_loss: 1.9625 - val_accuracy: 0.2830\n",
            "Epoch 3/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9408 - accuracy: 0.2929 - val_loss: 1.9574 - val_accuracy: 0.2870\n",
            "Epoch 4/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9350 - accuracy: 0.2947 - val_loss: 1.9518 - val_accuracy: 0.2851\n",
            "Epoch 5/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9295 - accuracy: 0.2977 - val_loss: 1.9484 - val_accuracy: 0.2872\n",
            "Epoch 6/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9240 - accuracy: 0.2987 - val_loss: 1.9442 - val_accuracy: 0.2954\n",
            "Epoch 7/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9183 - accuracy: 0.3015 - val_loss: 1.9416 - val_accuracy: 0.2935\n",
            "validate epoch:8\n",
            "Epoch 1/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9124 - accuracy: 0.3035 - val_loss: 1.9366 - val_accuracy: 0.2926\n",
            "Epoch 2/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9074 - accuracy: 0.3054 - val_loss: 1.9277 - val_accuracy: 0.2974\n",
            "Epoch 3/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9020 - accuracy: 0.3068 - val_loss: 1.9235 - val_accuracy: 0.2980\n",
            "Epoch 4/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8973 - accuracy: 0.3077 - val_loss: 1.9216 - val_accuracy: 0.2991\n",
            "Epoch 5/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8921 - accuracy: 0.3104 - val_loss: 1.9174 - val_accuracy: 0.3000\n",
            "Epoch 6/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8875 - accuracy: 0.3114 - val_loss: 1.9125 - val_accuracy: 0.3013\n",
            "Epoch 7/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8830 - accuracy: 0.3125 - val_loss: 1.9090 - val_accuracy: 0.3012\n",
            "Epoch 8/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8786 - accuracy: 0.3135 - val_loss: 1.9128 - val_accuracy: 0.2956\n",
            "validate epoch:9\n",
            "Epoch 1/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8743 - accuracy: 0.3151 - val_loss: 1.9043 - val_accuracy: 0.2991\n",
            "Epoch 2/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8706 - accuracy: 0.3158 - val_loss: 1.9017 - val_accuracy: 0.3030\n",
            "Epoch 3/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8665 - accuracy: 0.3164 - val_loss: 1.8998 - val_accuracy: 0.3031\n",
            "Epoch 4/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8635 - accuracy: 0.3171 - val_loss: 1.8978 - val_accuracy: 0.3018\n",
            "Epoch 5/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8598 - accuracy: 0.3182 - val_loss: 1.8902 - val_accuracy: 0.3042\n",
            "Epoch 6/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8566 - accuracy: 0.3182 - val_loss: 1.8900 - val_accuracy: 0.3023\n",
            "Epoch 7/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8537 - accuracy: 0.3210 - val_loss: 1.8871 - val_accuracy: 0.3080\n",
            "Epoch 8/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8506 - accuracy: 0.3215 - val_loss: 1.8832 - val_accuracy: 0.3039\n",
            "Epoch 9/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8477 - accuracy: 0.3219 - val_loss: 1.8821 - val_accuracy: 0.3079\n",
            "validate epoch:10\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8452 - accuracy: 0.3241 - val_loss: 1.8839 - val_accuracy: 0.3038\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8422 - accuracy: 0.3250 - val_loss: 1.8844 - val_accuracy: 0.3074\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8398 - accuracy: 0.3305 - val_loss: 1.8767 - val_accuracy: 0.3169\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8380 - accuracy: 0.3340 - val_loss: 1.8725 - val_accuracy: 0.3182\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8356 - accuracy: 0.3341 - val_loss: 1.8750 - val_accuracy: 0.3149\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8335 - accuracy: 0.3348 - val_loss: 1.8705 - val_accuracy: 0.3164\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8310 - accuracy: 0.3342 - val_loss: 1.8700 - val_accuracy: 0.3168\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8293 - accuracy: 0.3350 - val_loss: 1.8724 - val_accuracy: 0.3176\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8272 - accuracy: 0.3363 - val_loss: 1.8720 - val_accuracy: 0.3143\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8258 - accuracy: 0.3365 - val_loss: 1.8657 - val_accuracy: 0.3155\n",
            "{'cnn': [0.4327999949455261, 0.5633000135421753, 0.63919997215271, 0.695900022983551, 0.7336999773979187, 0.7494000196456909, 0.7631999850273132, 0.7757999897003174, 0.7749000191688538, 0.7870000004768372], 'Dense 0': [0.3133000135421753, 0.362199991941452, 0.3734999895095825, 0.3903000056743622, 0.3901999890804291, 0.3815999925136566, 0.3950999975204468, 0.3903999924659729, 0.4011000096797943, 0.4016000032424927], 'Dense 1': [0.1987999975681305, 0.23579999804496765, 0.25929999351501465, 0.2671999931335449, 0.2987000048160553, 0.3068000078201294, 0.3174000084400177, 0.33500000834465027, 0.35109999775886536, 0.3555000126361847], 'Dense 2': [0.11339999735355377, 0.2085999995470047, 0.24120000004768372, 0.24650000035762787, 0.26899999380111694, 0.2824999988079071, 0.29350000619888306, 0.2955999970436096, 0.30790001153945923, 0.3154999911785126]}\n",
            "validate epoch:1\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.3082 - accuracy: 0.0875 - val_loss: 2.3021 - val_accuracy: 0.0898\n",
            "validate epoch:2\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.2924 - accuracy: 0.1169 - val_loss: 2.2805 - val_accuracy: 0.1662\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.2658 - accuracy: 0.1787 - val_loss: 2.2537 - val_accuracy: 0.1895\n",
            "validate epoch:3\n",
            "Epoch 1/3\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.2392 - accuracy: 0.1923 - val_loss: 2.2284 - val_accuracy: 0.1899\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.2138 - accuracy: 0.1913 - val_loss: 2.2042 - val_accuracy: 0.1906\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.1896 - accuracy: 0.1921 - val_loss: 2.1821 - val_accuracy: 0.1881\n",
            "validate epoch:4\n",
            "Epoch 1/4\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.1675 - accuracy: 0.1926 - val_loss: 2.1620 - val_accuracy: 0.1890\n",
            "Epoch 2/4\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 2.1473 - accuracy: 0.1933 - val_loss: 2.1433 - val_accuracy: 0.1932\n",
            "Epoch 3/4\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.1291 - accuracy: 0.1965 - val_loss: 2.1269 - val_accuracy: 0.1954\n",
            "Epoch 4/4\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.1133 - accuracy: 0.1984 - val_loss: 2.1125 - val_accuracy: 0.1955\n",
            "validate epoch:5\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0993 - accuracy: 0.1977 - val_loss: 2.1034 - val_accuracy: 0.1932\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0870 - accuracy: 0.1977 - val_loss: 2.0889 - val_accuracy: 0.1962\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0761 - accuracy: 0.1992 - val_loss: 2.0878 - val_accuracy: 0.1935\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0668 - accuracy: 0.2001 - val_loss: 2.0748 - val_accuracy: 0.1938\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0583 - accuracy: 0.2007 - val_loss: 2.0664 - val_accuracy: 0.1989\n",
            "validate epoch:6\n",
            "Epoch 1/6\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0507 - accuracy: 0.2013 - val_loss: 2.0632 - val_accuracy: 0.1941\n",
            "Epoch 2/6\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0447 - accuracy: 0.2029 - val_loss: 2.0604 - val_accuracy: 0.2044\n",
            "Epoch 3/6\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0382 - accuracy: 0.2111 - val_loss: 2.0484 - val_accuracy: 0.2057\n",
            "Epoch 4/6\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0333 - accuracy: 0.2109 - val_loss: 2.0442 - val_accuracy: 0.2035\n",
            "Epoch 5/6\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0280 - accuracy: 0.2106 - val_loss: 2.0416 - val_accuracy: 0.2021\n",
            "Epoch 6/6\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0234 - accuracy: 0.2090 - val_loss: 2.0355 - val_accuracy: 0.2020\n",
            "validate epoch:7\n",
            "Epoch 1/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0188 - accuracy: 0.2118 - val_loss: 2.0352 - val_accuracy: 0.2146\n",
            "Epoch 2/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0145 - accuracy: 0.2219 - val_loss: 2.0362 - val_accuracy: 0.2219\n",
            "Epoch 3/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0109 - accuracy: 0.2207 - val_loss: 2.0306 - val_accuracy: 0.2193\n",
            "Epoch 4/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0064 - accuracy: 0.2224 - val_loss: 2.0193 - val_accuracy: 0.2205\n",
            "Epoch 5/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0019 - accuracy: 0.2256 - val_loss: 2.0156 - val_accuracy: 0.2234\n",
            "Epoch 6/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9980 - accuracy: 0.2278 - val_loss: 2.0247 - val_accuracy: 0.2174\n",
            "Epoch 7/7\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9918 - accuracy: 0.2299 - val_loss: 2.0049 - val_accuracy: 0.2276\n",
            "validate epoch:8\n",
            "Epoch 1/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9871 - accuracy: 0.2353 - val_loss: 2.0004 - val_accuracy: 0.2310\n",
            "Epoch 2/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9818 - accuracy: 0.2421 - val_loss: 1.9969 - val_accuracy: 0.2398\n",
            "Epoch 3/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9757 - accuracy: 0.2560 - val_loss: 1.9905 - val_accuracy: 0.2554\n",
            "Epoch 4/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9715 - accuracy: 0.2604 - val_loss: 1.9863 - val_accuracy: 0.2544\n",
            "Epoch 5/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9661 - accuracy: 0.2643 - val_loss: 1.9811 - val_accuracy: 0.2613\n",
            "Epoch 6/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9621 - accuracy: 0.2681 - val_loss: 1.9779 - val_accuracy: 0.2667\n",
            "Epoch 7/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9570 - accuracy: 0.2708 - val_loss: 1.9862 - val_accuracy: 0.2558\n",
            "Epoch 8/8\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9524 - accuracy: 0.2744 - val_loss: 1.9691 - val_accuracy: 0.2635\n",
            "validate epoch:9\n",
            "Epoch 1/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9478 - accuracy: 0.2765 - val_loss: 1.9650 - val_accuracy: 0.2690\n",
            "Epoch 2/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9428 - accuracy: 0.2794 - val_loss: 1.9621 - val_accuracy: 0.2718\n",
            "Epoch 3/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9384 - accuracy: 0.2821 - val_loss: 1.9565 - val_accuracy: 0.2742\n",
            "Epoch 4/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9344 - accuracy: 0.2849 - val_loss: 1.9559 - val_accuracy: 0.2810\n",
            "Epoch 5/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9297 - accuracy: 0.2853 - val_loss: 1.9520 - val_accuracy: 0.2721\n",
            "Epoch 6/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9251 - accuracy: 0.2864 - val_loss: 1.9592 - val_accuracy: 0.2726\n",
            "Epoch 7/9\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.9208 - accuracy: 0.2880 - val_loss: 1.9506 - val_accuracy: 0.2776\n",
            "Epoch 8/9\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9164 - accuracy: 0.2906 - val_loss: 1.9460 - val_accuracy: 0.2775\n",
            "Epoch 9/9\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9120 - accuracy: 0.2916 - val_loss: 1.9388 - val_accuracy: 0.2755\n",
            "validate epoch:10\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9077 - accuracy: 0.2917 - val_loss: 1.9347 - val_accuracy: 0.2795\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9033 - accuracy: 0.2945 - val_loss: 1.9331 - val_accuracy: 0.2804\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8998 - accuracy: 0.2953 - val_loss: 1.9343 - val_accuracy: 0.2790\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8953 - accuracy: 0.2968 - val_loss: 1.9387 - val_accuracy: 0.2780\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8919 - accuracy: 0.2978 - val_loss: 1.9248 - val_accuracy: 0.2833\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8881 - accuracy: 0.2987 - val_loss: 1.9217 - val_accuracy: 0.2825\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8843 - accuracy: 0.3002 - val_loss: 1.9185 - val_accuracy: 0.2847\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8816 - accuracy: 0.3012 - val_loss: 1.9175 - val_accuracy: 0.2868\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8780 - accuracy: 0.3017 - val_loss: 1.9121 - val_accuracy: 0.2863\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8747 - accuracy: 0.3032 - val_loss: 1.9204 - val_accuracy: 0.2857\n",
            "{'cnn': [0.4327999949455261, 0.5633000135421753, 0.63919997215271, 0.695900022983551, 0.7336999773979187, 0.7494000196456909, 0.7631999850273132, 0.7757999897003174, 0.7749000191688538, 0.7870000004768372], 'Dense 0': [0.3133000135421753, 0.362199991941452, 0.3734999895095825, 0.3903000056743622, 0.3901999890804291, 0.3815999925136566, 0.3950999975204468, 0.3903999924659729, 0.4011000096797943, 0.4016000032424927], 'Dense 1': [0.1987999975681305, 0.23579999804496765, 0.25929999351501465, 0.2671999931335449, 0.2987000048160553, 0.3068000078201294, 0.3174000084400177, 0.33500000834465027, 0.35109999775886536, 0.3555000126361847], 'Dense 2': [0.11339999735355377, 0.2085999995470047, 0.24120000004768372, 0.24650000035762787, 0.26899999380111694, 0.2824999988079071, 0.29350000619888306, 0.2955999970436096, 0.30790001153945923, 0.3154999911785126], 'Dense 3': [0.08980000019073486, 0.18950000405311584, 0.18809999525547028, 0.19550000131130219, 0.1988999992609024, 0.20200000703334808, 0.22759999334812164, 0.26350000500679016, 0.27549999952316284, 0.2856999933719635]}\n",
            "validate epoch:1\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 2.2656 - accuracy: 0.2042 - val_loss: 2.2537 - val_accuracy: 0.1989\n",
            "validate epoch:2\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 2.2386 - accuracy: 0.2111 - val_loss: 2.2298 - val_accuracy: 0.2033\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.2144 - accuracy: 0.2131 - val_loss: 2.2076 - val_accuracy: 0.2027\n",
            "validate epoch:3\n",
            "Epoch 1/3\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 2.1919 - accuracy: 0.2148 - val_loss: 2.1853 - val_accuracy: 0.2083\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.1702 - accuracy: 0.2170 - val_loss: 2.1681 - val_accuracy: 0.2037\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.1494 - accuracy: 0.2197 - val_loss: 2.1492 - val_accuracy: 0.2075\n",
            "validate epoch:4\n",
            "Epoch 1/4\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 2.1305 - accuracy: 0.2219 - val_loss: 2.1322 - val_accuracy: 0.2072\n",
            "Epoch 2/4\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.1120 - accuracy: 0.2221 - val_loss: 2.1167 - val_accuracy: 0.2046\n",
            "Epoch 3/4\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.0946 - accuracy: 0.2387 - val_loss: 2.0983 - val_accuracy: 0.2304\n",
            "Epoch 4/4\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 2.0779 - accuracy: 0.2417 - val_loss: 2.0946 - val_accuracy: 0.2227\n",
            "validate epoch:5\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 2.0624 - accuracy: 0.2395 - val_loss: 2.0736 - val_accuracy: 0.2233\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 2.0482 - accuracy: 0.2390 - val_loss: 2.0589 - val_accuracy: 0.2281\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 2.0339 - accuracy: 0.2388 - val_loss: 2.0502 - val_accuracy: 0.2323\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 2.0192 - accuracy: 0.2392 - val_loss: 2.0361 - val_accuracy: 0.2261\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 2.0069 - accuracy: 0.2396 - val_loss: 2.0286 - val_accuracy: 0.2245\n",
            "validate epoch:6\n",
            "Epoch 1/6\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9953 - accuracy: 0.2401 - val_loss: 2.0167 - val_accuracy: 0.2286\n",
            "Epoch 2/6\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9839 - accuracy: 0.2401 - val_loss: 2.0104 - val_accuracy: 0.2291\n",
            "Epoch 3/6\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.9740 - accuracy: 0.2398 - val_loss: 2.0033 - val_accuracy: 0.2285\n",
            "Epoch 4/6\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9650 - accuracy: 0.2399 - val_loss: 2.0001 - val_accuracy: 0.2284\n",
            "Epoch 5/6\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9573 - accuracy: 0.2398 - val_loss: 1.9906 - val_accuracy: 0.2292\n",
            "Epoch 6/6\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9495 - accuracy: 0.2402 - val_loss: 1.9863 - val_accuracy: 0.2261\n",
            "validate epoch:7\n",
            "Epoch 1/7\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9440 - accuracy: 0.2460 - val_loss: 1.9848 - val_accuracy: 0.2480\n",
            "Epoch 2/7\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.9378 - accuracy: 0.2577 - val_loss: 1.9781 - val_accuracy: 0.2386\n",
            "Epoch 3/7\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.9329 - accuracy: 0.2510 - val_loss: 1.9751 - val_accuracy: 0.2389\n",
            "Epoch 4/7\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9287 - accuracy: 0.2520 - val_loss: 1.9718 - val_accuracy: 0.2415\n",
            "Epoch 5/7\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9234 - accuracy: 0.2524 - val_loss: 1.9713 - val_accuracy: 0.2355\n",
            "Epoch 6/7\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9196 - accuracy: 0.2532 - val_loss: 1.9730 - val_accuracy: 0.2376\n",
            "Epoch 7/7\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9158 - accuracy: 0.2534 - val_loss: 1.9686 - val_accuracy: 0.2371\n",
            "validate epoch:8\n",
            "Epoch 1/8\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.9129 - accuracy: 0.2543 - val_loss: 1.9667 - val_accuracy: 0.2389\n",
            "Epoch 2/8\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9089 - accuracy: 0.2696 - val_loss: 1.9637 - val_accuracy: 0.2627\n",
            "Epoch 3/8\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9069 - accuracy: 0.2802 - val_loss: 1.9600 - val_accuracy: 0.2652\n",
            "Epoch 4/8\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9040 - accuracy: 0.2847 - val_loss: 1.9584 - val_accuracy: 0.2645\n",
            "Epoch 5/8\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.9014 - accuracy: 0.2854 - val_loss: 1.9621 - val_accuracy: 0.2643\n",
            "Epoch 6/8\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8986 - accuracy: 0.2874 - val_loss: 1.9720 - val_accuracy: 0.2747\n",
            "Epoch 7/8\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8961 - accuracy: 0.2901 - val_loss: 1.9729 - val_accuracy: 0.2680\n",
            "Epoch 8/8\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8933 - accuracy: 0.2909 - val_loss: 1.9563 - val_accuracy: 0.2715\n",
            "validate epoch:9\n",
            "Epoch 1/9\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.8905 - accuracy: 0.2923 - val_loss: 1.9689 - val_accuracy: 0.2708\n",
            "Epoch 2/9\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8886 - accuracy: 0.2923 - val_loss: 1.9499 - val_accuracy: 0.2734\n",
            "Epoch 3/9\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8861 - accuracy: 0.2939 - val_loss: 1.9527 - val_accuracy: 0.2748\n",
            "Epoch 4/9\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8840 - accuracy: 0.2939 - val_loss: 1.9457 - val_accuracy: 0.2752\n",
            "Epoch 5/9\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8806 - accuracy: 0.2950 - val_loss: 1.9437 - val_accuracy: 0.2796\n",
            "Epoch 6/9\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8786 - accuracy: 0.2957 - val_loss: 1.9512 - val_accuracy: 0.2710\n",
            "Epoch 7/9\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8758 - accuracy: 0.2960 - val_loss: 1.9461 - val_accuracy: 0.2729\n",
            "Epoch 8/9\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8750 - accuracy: 0.2959 - val_loss: 1.9391 - val_accuracy: 0.2756\n",
            "Epoch 9/9\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8718 - accuracy: 0.2982 - val_loss: 1.9370 - val_accuracy: 0.2807\n",
            "validate epoch:10\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8692 - accuracy: 0.2978 - val_loss: 1.9418 - val_accuracy: 0.2785\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8671 - accuracy: 0.3000 - val_loss: 1.9483 - val_accuracy: 0.2704\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8663 - accuracy: 0.2983 - val_loss: 1.9406 - val_accuracy: 0.2746\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8631 - accuracy: 0.2995 - val_loss: 1.9304 - val_accuracy: 0.2807\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8619 - accuracy: 0.3000 - val_loss: 1.9355 - val_accuracy: 0.2792\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8591 - accuracy: 0.3007 - val_loss: 1.9291 - val_accuracy: 0.2808\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8570 - accuracy: 0.3012 - val_loss: 1.9311 - val_accuracy: 0.2807\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8559 - accuracy: 0.3025 - val_loss: 1.9261 - val_accuracy: 0.2824\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 1.8536 - accuracy: 0.3027 - val_loss: 1.9331 - val_accuracy: 0.2830\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.8523 - accuracy: 0.3029 - val_loss: 1.9261 - val_accuracy: 0.2835\n",
            "{'cnn': [0.4327999949455261, 0.5633000135421753, 0.63919997215271, 0.695900022983551, 0.7336999773979187, 0.7494000196456909, 0.7631999850273132, 0.7757999897003174, 0.7749000191688538, 0.7870000004768372], 'Dense 0': [0.3133000135421753, 0.362199991941452, 0.3734999895095825, 0.3903000056743622, 0.3901999890804291, 0.3815999925136566, 0.3950999975204468, 0.3903999924659729, 0.4011000096797943, 0.4016000032424927], 'Dense 1': [0.1987999975681305, 0.23579999804496765, 0.25929999351501465, 0.2671999931335449, 0.2987000048160553, 0.3068000078201294, 0.3174000084400177, 0.33500000834465027, 0.35109999775886536, 0.3555000126361847], 'Dense 2': [0.11339999735355377, 0.2085999995470047, 0.24120000004768372, 0.24650000035762787, 0.26899999380111694, 0.2824999988079071, 0.29350000619888306, 0.2955999970436096, 0.30790001153945923, 0.3154999911785126], 'Dense 3': [0.08980000019073486, 0.18950000405311584, 0.18809999525547028, 0.19550000131130219, 0.1988999992609024, 0.20200000703334808, 0.22759999334812164, 0.26350000500679016, 0.27549999952316284, 0.2856999933719635], 'Dense 4': [0.1988999992609024, 0.20270000398159027, 0.20749999582767487, 0.22269999980926514, 0.22450000047683716, 0.22609999775886536, 0.2371000051498413, 0.27149999141693115, 0.2806999981403351, 0.28349998593330383]}\n",
            "validate epoch:1\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 2.2366 - accuracy: 0.1476 - val_loss: 2.0730 - val_accuracy: 0.2068\n",
            "validate epoch:2\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 2.0669 - accuracy: 0.2149 - val_loss: 1.9485 - val_accuracy: 0.2960\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.9758 - accuracy: 0.2629 - val_loss: 1.8541 - val_accuracy: 0.3356\n",
            "validate epoch:3\n",
            "Epoch 1/3\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.9249 - accuracy: 0.2890 - val_loss: 1.8046 - val_accuracy: 0.3495\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.8853 - accuracy: 0.3123 - val_loss: 1.7792 - val_accuracy: 0.3640\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.8538 - accuracy: 0.3228 - val_loss: 1.7714 - val_accuracy: 0.3732\n",
            "validate epoch:4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DenpmG2rQEwb"
      },
      "source": [
        "performance_dict = {'cnn': [0.4327999949455261, 0.5633000135421753, 0.63919997215271, 0.695900022983551, 0.7336999773979187, 0.7494000196456909, 0.7631999850273132, 0.7757999897003174, 0.7749000191688538, 0.7870000004768372], 'Dense 0': [0.3133000135421753, 0.362199991941452, 0.3734999895095825, 0.3903000056743622, 0.3901999890804291, 0.3815999925136566, 0.3950999975204468, 0.3903999924659729, 0.4011000096797943, 0.4016000032424927], 'Dense 1': [0.1987999975681305, 0.23579999804496765, 0.25929999351501465, 0.2671999931335449, 0.2987000048160553, 0.3068000078201294, 0.3174000084400177, 0.33500000834465027, 0.35109999775886536, 0.3555000126361847], 'Dense 2': [0.11339999735355377, 0.2085999995470047, 0.24120000004768372, 0.24650000035762787, 0.26899999380111694, 0.2824999988079071, 0.29350000619888306, 0.2955999970436096, 0.30790001153945923, 0.3154999911785126], 'Dense 3': [0.08980000019073486, 0.18950000405311584, 0.18809999525547028, 0.19550000131130219, 0.1988999992609024, 0.20200000703334808, 0.22759999334812164, 0.26350000500679016, 0.27549999952316284, 0.2856999933719635], 'Dense 4': [0.1988999992609024, 0.20270000398159027, 0.20749999582767487, 0.22269999980926514, 0.22450000047683716, 0.22609999775886536, 0.2371000051498413, 0.27149999141693115, 0.2806999981403351, 0.28349998593330383]}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJzwGBmgWLwY",
        "outputId": "fdc3a9b4-424b-4b12-bf61-037ec8e51881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "performance_dict"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dense 0': [0.3133000135421753,\n",
              "  0.362199991941452,\n",
              "  0.3734999895095825,\n",
              "  0.3903000056743622,\n",
              "  0.3901999890804291,\n",
              "  0.3815999925136566,\n",
              "  0.3950999975204468,\n",
              "  0.3903999924659729,\n",
              "  0.4011000096797943,\n",
              "  0.4016000032424927],\n",
              " 'Dense 1': [0.1987999975681305,\n",
              "  0.23579999804496765,\n",
              "  0.25929999351501465,\n",
              "  0.2671999931335449,\n",
              "  0.2987000048160553,\n",
              "  0.3068000078201294,\n",
              "  0.3174000084400177,\n",
              "  0.33500000834465027,\n",
              "  0.35109999775886536,\n",
              "  0.3555000126361847],\n",
              " 'Dense 2': [0.11339999735355377,\n",
              "  0.2085999995470047,\n",
              "  0.24120000004768372,\n",
              "  0.24650000035762787,\n",
              "  0.26899999380111694,\n",
              "  0.2824999988079071,\n",
              "  0.29350000619888306,\n",
              "  0.2955999970436096,\n",
              "  0.30790001153945923,\n",
              "  0.3154999911785126],\n",
              " 'Dense 3': [0.08980000019073486,\n",
              "  0.18950000405311584,\n",
              "  0.18809999525547028,\n",
              "  0.19550000131130219,\n",
              "  0.1988999992609024,\n",
              "  0.20200000703334808,\n",
              "  0.22759999334812164,\n",
              "  0.26350000500679016,\n",
              "  0.27549999952316284,\n",
              "  0.2856999933719635],\n",
              " 'Dense 4': [0.1988999992609024,\n",
              "  0.20270000398159027,\n",
              "  0.20749999582767487,\n",
              "  0.22269999980926514,\n",
              "  0.22450000047683716,\n",
              "  0.22609999775886536,\n",
              "  0.2371000051498413,\n",
              "  0.27149999141693115,\n",
              "  0.2806999981403351,\n",
              "  0.28349998593330383],\n",
              " 'cnn': [0.4327999949455261,\n",
              "  0.5633000135421753,\n",
              "  0.63919997215271,\n",
              "  0.695900022983551,\n",
              "  0.7336999773979187,\n",
              "  0.7494000196456909,\n",
              "  0.7631999850273132,\n",
              "  0.7757999897003174,\n",
              "  0.7749000191688538,\n",
              "  0.7870000004768372]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQxnwxFjbKO5"
      },
      "source": [
        "df = pd.DataFrame(performance_dict)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHIC5XuhbKYV",
        "outputId": "18e0ba43-1f11-4430-9b17-6283296fa8e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cnn</th>\n",
              "      <th>Dense 0</th>\n",
              "      <th>Dense 1</th>\n",
              "      <th>Dense 2</th>\n",
              "      <th>Dense 3</th>\n",
              "      <th>Dense 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.3133</td>\n",
              "      <td>0.1988</td>\n",
              "      <td>0.1134</td>\n",
              "      <td>0.0898</td>\n",
              "      <td>0.1989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.5633</td>\n",
              "      <td>0.3622</td>\n",
              "      <td>0.2358</td>\n",
              "      <td>0.2086</td>\n",
              "      <td>0.1895</td>\n",
              "      <td>0.2027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.6392</td>\n",
              "      <td>0.3735</td>\n",
              "      <td>0.2593</td>\n",
              "      <td>0.2412</td>\n",
              "      <td>0.1881</td>\n",
              "      <td>0.2075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.6959</td>\n",
              "      <td>0.3903</td>\n",
              "      <td>0.2672</td>\n",
              "      <td>0.2465</td>\n",
              "      <td>0.1955</td>\n",
              "      <td>0.2227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7337</td>\n",
              "      <td>0.3902</td>\n",
              "      <td>0.2987</td>\n",
              "      <td>0.2690</td>\n",
              "      <td>0.1989</td>\n",
              "      <td>0.2245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7494</td>\n",
              "      <td>0.3816</td>\n",
              "      <td>0.3068</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.2020</td>\n",
              "      <td>0.2261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7632</td>\n",
              "      <td>0.3951</td>\n",
              "      <td>0.3174</td>\n",
              "      <td>0.2935</td>\n",
              "      <td>0.2276</td>\n",
              "      <td>0.2371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7758</td>\n",
              "      <td>0.3904</td>\n",
              "      <td>0.3350</td>\n",
              "      <td>0.2956</td>\n",
              "      <td>0.2635</td>\n",
              "      <td>0.2715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7749</td>\n",
              "      <td>0.4011</td>\n",
              "      <td>0.3511</td>\n",
              "      <td>0.3079</td>\n",
              "      <td>0.2755</td>\n",
              "      <td>0.2807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.7870</td>\n",
              "      <td>0.4016</td>\n",
              "      <td>0.3555</td>\n",
              "      <td>0.3155</td>\n",
              "      <td>0.2857</td>\n",
              "      <td>0.2835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      cnn  Dense 0  Dense 1  Dense 2  Dense 3  Dense 4\n",
              "0  0.4328   0.3133   0.1988   0.1134   0.0898   0.1989\n",
              "1  0.5633   0.3622   0.2358   0.2086   0.1895   0.2027\n",
              "2  0.6392   0.3735   0.2593   0.2412   0.1881   0.2075\n",
              "3  0.6959   0.3903   0.2672   0.2465   0.1955   0.2227\n",
              "4  0.7337   0.3902   0.2987   0.2690   0.1989   0.2245\n",
              "5  0.7494   0.3816   0.3068   0.2825   0.2020   0.2261\n",
              "6  0.7632   0.3951   0.3174   0.2935   0.2276   0.2371\n",
              "7  0.7758   0.3904   0.3350   0.2956   0.2635   0.2715\n",
              "8  0.7749   0.4011   0.3511   0.3079   0.2755   0.2807\n",
              "9  0.7870   0.4016   0.3555   0.3155   0.2857   0.2835"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNDd9BsYbKca",
        "outputId": "afaffb6b-fd3c-4f8e-a02f-9584a11f9976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "fig = df.plot()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde3ycZZ3//9c155lkZnI+NOeW0qahpfQMRaCcykFBV1TAFRGV9YDfXVF20d11FfeAu+xBOShVPO6BXfmtiCsKagtCEWixUNumlNKmbdKc02QmmfPc1++PezKZHNqm7aSZJJ8nj3ncp2vuuSal71y97uu+bqW1RgghxMxnme4KCCGEyA4JdCGEmCUk0IUQYpaQQBdCiFlCAl0IIWYJ23R9cElJia6vr5+ujxdCiBnptdde69Fal050bNoCvb6+nu3bt0/XxwshxIyklDp0vGPS5SKEELPEpAJdKXWNUupNpdR+pdS9ExyvVUptUUrtUErtVEpdl/2qCiGEOJGTBrpSygo8DFwLLAFuUUotGVPsr4D/0VpfANwMPJLtigohhDixyfShrwH2a60PACilHgduBPZklNGAL7XuB46eTmXi8Titra1EIpHTefuc43K5qK6uxm63T3dVhBA5YDKBXgUcydhuBdaOKfNl4Fml1GeAPODK06lMa2srXq+X+vp6lFKnc4o5Q2tNb28vra2tNDQ0THd1hBA5IFsXRW8Bvq+1rgauA36klBp3bqXUnUqp7Uqp7d3d3eNOEolEKC4uljCfBKUUxcXF8q8ZIUTaZAK9DajJ2K5O7cv0UeB/ALTWvwNcQMnYE2mtN2mtV2mtV5WWTjiMUsL8FMjPSgiRaTJdLtuAhUqpBswgvxm4dUyZw8AVwPeVUo2YgT6+CS6EEHOIYWh6h2J0BiJ0BSN0BqJ0BiJcvriMZdUFWf+8kwa61jqhlLoLeAawAt/VWu9WSt0HbNdaPwV8Dvi2UuqzmBdIb9cy0boQYpbSWtMfitOZEdJdgZH1zmCUrkCE7mCUhDE+CovzndMT6KnKPw08PWbflzLW9wDrs1s1IYQ4u7TWBKOJ0eE8HNijwjtKLGmMe3+Bx06510WZz8nCshLKfU7KfS7KvK70ekm+E4dtau7pnLZb/3PZD3/4Qx544AGUUixbtgyr1YrP52P79u10dHTwj//4j9x0000899xzfPnLX6akpIRdu3axcuVK/v3f/136tsWcN9yC7QhE6AhECEWTWJR53ceiwKIUFsvw9sg+NXwstW9U+YzjI+WOU8Yy/pwKGAjH6QxEU+EcSa2PbmGH48lx38frslHmNQN5dX0RZT4n5V4X5b6RoC71OnHZrWf/h50hZwP9Kz/bzZ6jgayec8k8H3/zrqYTltm9ezd/+7d/y0svvURJSQl9fX3cfffdtLe38+KLL7J3715uuOEGbrrpJgB27NjB7t27mTdvHuvXr2fr1q1cfPHFWa23ELkkljBSYWiGdcfA8HqUzgFzX2cgQjQxvgWba9x2KxV+F2Veswsk3aL2uSj3Dq878ThyNipHmRm1PIs2b97M+973PkpKzEE6RUVFALz73e/GYrGwZMkSOjs70+XXrFlDdXU1AMuXL6elpUUCXcxIWmsC4US6VT0czpnrnYEIPYOxce912CxU+s0W6/KaAipS6xU+FxV+J/lOOxqNYYChNVqbS/NlfraRsW/k+HD5kfeaXdKZ5YffP9H5M96vwee2pbpEzJZ1vtM2q/5FnbOBfrKW9NnmdDrT65nXezP3W61WEonEWa2XEJMRTxp0B6PpFvVIq3r0eiQ+vlVdlOdIhbOTZdX+dFCX+1OB7XNR4LHPqmCcqXI20KfL5Zdfznve8x7uvvtuiouL6evrm+4qCXFCSUPTHYzS1h/maH+Y9oEwR/sjqXUzqHsGo4wdd+awWijzOanwuTivys+VjeUjLetUWJf5nDht09svLCZPAn2MpqYm/vIv/5JLL70Uq9XKBRdcMN1VEnPYcDfI0QEzrI/2hzk6kArr/ght/WE6A5FxQ+PynTbmFbio9LtZUukbaU37nekWdlGeQ1rVs4yaruHiq1at0mMfcNHc3ExjY+O01Gemkp/ZzBaJJ+kYiKQCO5JuYbf1R2hPBfhQbPSoC5tFUZkK66oCN5V+F/MKUusF5rrPJRO2zVZKqde01qsmOiYtdCGmiGFoegbNrpD2VKu6LdWyHg7wnsHouPeV5DuYV+BmfmkeFy8sSYW2m3mpsC7Jd2K1SMtajCeBLsRp0lrTNxTjyLEwh/tCHEm9DveFOHIsRMdAhHhy9L+APQ4r8wrczCtw0zTPlwpqN/NSrewKv2vaxzKLmUsCXYgTiMSTtB4LcaTPDO3DmaHdFxrXHVKS76SmyM0FNYVULRsJ6uHuEZ97dg2TE7lFAl3MaYah6QpGxwX1kWPmemdgdJeIy26htshDbZGHdfOL0+s1RR5qitwz5gYUMTvJ/31i1gtG4ukWdmsqqIdfrcfCxDLuaFQKKn0uaoo8XLKwlJqMwK4t8lCSLyNDRO6SQBezRmcgwvP7umnpGRrV4j4Wio8q53XZqCv2sKjcy1WN5anWtRnY8wpcMu5azFgS6GNYrVaWLl1KPB7HZrNx22238dnPfhaLZWpmRzuRf/iHf+Cxxx7DarXyjW98g40bN571OuS6A92DPLO7k2d2d/D6kX7AHNZXXeimpsjDtUsr090itUUeago9+D0ypE/MThLoY7jdbl5//XUAurq6uPXWWwkEAnzlK185q/XYs2cPjz/+OLt37+bo0aNceeWV7Nu3D6t1brcetdbsPhrgmd0dPLO7g32dgwAsrfLz+avP5aolFZxTli/D+sScdPabnTNIWVkZmzZt4qGHHkJrTTKZ5J577mH16tUsW7aMRx99FIDnnnuOyy67jJtuuonFixfzwQ9+MD3fy7333suSJUtYtmwZn//85wHo7u7mve99L6tXr2b16tVs3bp13Gf/9Kc/5eabb8bpdNLQ0MA555zDq6++eva+fA5JGpqXD/TylZ/t5uKvbeGdD77Iw1v2U5Tn4G/etYSt917Ozz5zMXddvpBFFV4JczFn5W4L/Rf3QscfsnvOiqVw7f2n9Jb58+eTTCbp6uripz/9KX6/n23bthGNRlm/fj1XX301MPE0uo2NjfzkJz9h7969KKXo7ze7BP70T/+Uz372s1x88cUcPnyYjRs30tzcPOpz29raWLduXXq7urqatraxj3KdvSLxJC+93cMvd3Xw6+Yu+oZiOGwW3nFOCX96xUKuaCyjON958hMJMYfkbqDnoGeffZadO3fyxBNPADAwMMBbb72Fw+GYcBrddevW4XK5+OhHP8o73/lO3vnOdwLw61//mj179qTPGwgEGBwcJD8//+x/qRwSjMTZ8mY3z+zu4Lm9XQzFknidNjYsLmNjUwWXLiol3yn/ywpxPLn7t+MUW9JT5cCBA1itVsrKytBa8+CDD467OPncc89NOI2uzWbj1Vdf5Te/+Q1PPPEEDz30EJs3b8YwDF5++WVcLtdxP7eqqoojR46kt1tbW6mqqsr+F5xmPYNRfr2nk1/u7uCl/b3EkgYl+Q5uWF7FxqZyLlxQLKNOhJik3A30HNDd3c0nPvEJ7rrrLpRSbNy4kW9+85tcfvnl2O129u3bd8KQHRwcJBQKcd1117F+/Xrmz58PwNVXX82DDz7IPffcA8Drr7/O8uXLR733hhtu4NZbb+Xuu+/m6NGjvPXWW6xZs2bqvuxZdKQvxDO7O3h2dyfbD/VhaKgpcnPbhXVsPK+CFbWF0g8uxGmYVKArpa4Bvg5Yge9ore8fc/xfgQ2pTQ9QprXO/iOtz4JwOMzy5cvTwxY/9KEPcffddwPwsY99jJaWFlasWIHWmtLSUp588snjnisYDHLjjTcSiUTQWvMv//IvAHzjG9/g05/+NMuWLSORSHDJJZfwrW99a9R7m5qaeP/738+SJUuw2Ww8/PDDM3aEi9aaNzuDPLPLHF64p918tODiCi+fuXwhG5sqaKz0yg07Qpyhk06fq5SyAvuAq4BWYBtwi9Z6z3HKfwa4QGt9x4nOK9PnZkeu/swMQ7PjSD/PpoYXtvSGUApW1BaysamcjU0V1BXnTXc1hZhxznT63DXAfq31gdTJHgduBCYMdOAW4G9Op6JiZoslDF4+0Mszuzv41Z5OuoJR7FbFhQtK+Pgl87lqSTll3uNfNxBCnJnJBHoVcCRjuxVYO1FBpVQd0ABsPs7xO4E7AWpra0+poiJ37e0I8J0XDvLM7g6CkQRuu5XLFpWysamCDYvL8LvlzkwhzoZsXxS9GXhCa52c6KDWehOwCcwulyx/tjjLfn/4GI9s2c+vm7vwOKxct7SSjU0VvGNhiczpLcQ0mEygtwE1GdvVqX0TuRn49JlWSuQurTVb9/fy8Jb9/O5ALwUeO3925UJuv6ieAo9juqsnxJw2mUDfBixUSjVgBvnNwK1jCymlFgOFwO+yWkOREwxD8+yeTh55bj87Wwco8zr5q+sbuWVNLXlys48QOeGkfxO11gml1F3AM5jDFr+rtd6tlLoP2K61fipV9GbgcT1dT50WUyKeNPjZG0d55Lm32d81SG2Rh3/4o6X80YoqueFHiBwzqaaV1vpp4Okx+740ZvvL2avW9MmV6XN7e3u56aab2LZtG7fffjsPPfTQWf38SDzJj7cf4VvPH6CtP8ziCi9fv3k51y+txGaVOd2EyEXyb+UxcmX6XJfLxVe/+lV27drFrl27ztrnBiNx/v3lwzz24kF6BqOsqC3gvhubuHxxmdz4I0SOk6bWCUzn9Ll5eXlcfPHFJ5zvJZt6B6P887Nvsv7+zXztl3tprPTy+J3r+P8+eRFXNJZLmAsxA+RsC/1rr36NvX17s3rOxUWL+Ys1f3FK75mu6XPPlqP9Yb79wgH+69XDRBMGG5dU8KkNC1hWPSNnbhBiTsvZQM9Fs2n63IM9Q3zrubf53x2taA03Lq/ik5fN55wy71mrgxAiu3I20E+1JT1Vpmv63Kmy++gAjzz3Nr/4Qzt2q4Vb19Ty8UvmU13oOet1EUJkV84Gei6Yzulzs21bSx+PbNnPlje78Tpt/MmlC7hjfQOlXnnqjxCzhQT6GLkyfS5AfX09gUCAWCzGk08+ybPPPsuSJUsm/V201jy/r5tHtrzNqy19FOc5uGfjIv54XZ3MryLELHTS6XOnikyfmx0T/cyShuaXuzp45Ln97D4aYJ7fxZ2XzOcDq2txO+RmICFmsjOdPlfMELGEwZM72vjW829zoGeI+aV5/ONNy3j38iocNhmhKsRsJ4E+C4RjSR7fdphNvz1A+0CEpnk+HvngCjY2Vcij3ISYQyTQZzBDa4KROOu/tpm+oRhrGoq4/73LuGRhidwIJMQcJIE+Q4ViCVqPhRkIJ1ha5eczl5/Dqvqi6a6WEGIaSaDPMElD0xmI0DMYxW61UJzv4Ad3rJjuagkhcoAE+gwSCMc52h8mljQozndS4XOyr19GrQghTDL0YQyr1cry5ctpamri/PPP55//+Z8xDOOs1+NXv/oVK1euZOnSpaxYuZL/+snTtPQOYVGKBaX5VBW4sZ7lKX2FELlNWuhj5Mr0uSUlJTz11FO4C0r57Suv8Se3vped+w5Q6nVikQueQogJSBPvBKZz+twl5y0j6vDTeizEeU3nEY9FKHAqCXMhxHHlbAu94+//nmhzdqfPdTYupuKLXzyl95zt6XMNrekJRukKRlEKqgrcbP7FU6xYsWLUBGBCCDFWzgZ6Lprq6XMtDhetx8JE4kn8bjvzCtzs29vMvffey7PPPnv2v7AQYkaZVKArpa4Bvo75kOjvaK3vn6DM+4EvAxp4Q2t965lU7FRb0lPlbEyfmx6K2D+I3WqhrjgPv9tOa2sr73nPe/jhD3/IggULzur3FkLMPCftQ1dKWYGHgWuBJcAtSqklY8osBL4ArNdaNwF/NgV1PeuON31uPB4HYN++fQwNDR33/YODgwwMDHDdddfxr//6r7zxxhvAyPS5YA5FfOo3W+kZjFKc7+Tc8nz8bjv9/f1cf/313H///axfv37qv6wQYsabTAt9DbBfa30AQCn1OHAjsCejzMeBh7XWxwC01l3ZrujZcramz/3kpz5FY9N5xOIJVq9bz2PffpQ858gfx0MPPcT+/fu57777uO+++wCzy6esrGwKv70QYiY76fS5SqmbgGu01h9LbX8IWKu1viujzJPAPmA9ZrfMl7XWv5zgXHcCdwLU1tauPHTo0Kjjc2H6XK01x0Jx2gfCGBrKvM4zGoo4F35mQogRZ2P6XBuwELgMqAZ+q5RaqrXuzyyktd4EbAJzPvQsffaMEY0naesPMxhNkOewUVXoxmWXOz2FENkxmUBvA2oytqtT+zK1Aq9orePAQaXUPsyA35aVWs5ww0MRO4NRLKmhiEV5DpkRUQiRVZO5sWgbsFAp1aCUcgA3A0+NKfMkZuscpVQJcC5wIIv1nLFCsQT7uwbpCETwuWycW+6lON8pYS6EyLqTttC11gml1F3AM5j949/VWu9WSt0HbNdaP5U6drVSag+QBO7RWvdOZcVz3dhZEYeHIgohxFSZVB+61vpp4Okx+76Usa6Bu1OvOS8QjtPWHyaeMSuiTKQlhJhqcqdoFsWTBu39YfrDcVw2K7Wl+aOGIgohxFSSZuMYpzN9rtaavqEY+zqDDEQSlPtcnFN+ZmH+6quvsnz5cpYvX87555/PT37yk9M+lxBibpDm4xinOn3uVA1FPO+889i+fTs2m4329nbOP/983vWud2GzyR+ZEGJi0kI/gZNNn/vAvz3Evq5Bnn/+OT55yw38xaduZ/nSpqxMn+vxeNLhHYlEZFSMEOKkcra598L/7KPnyGBWz1lSk8873n/uKb1noulzX3n1Vd5s6+Om665k3SUbqCn0sGvnG/x3FqbPzfTKK69wxx13cOjQIX70ox9J61wIcUKSEKdgePrc//zv/8EwNOGhIKGetqxNn5ufnz/q89auXcvu3btpbm7mwx/+MNdee216hkYhhBgrZwP9VFvSU2Xs9Ll/8/cPsHTdJVT63ZR6zSlzz3T63JNpbGwkPz+fXbt2sWrVhFM4CCGE9KGfyNjpcy+85HIe+/ajFLgslHqdWZk+F0hfhM108OBBEokEAIcOHWLv3r3U19dn9wsKIWaVnG2hT5fjTZ/bOxjlyvfcQktLC9dvWH/G0+d++tOfZtmyZSQSCS655BK+9a1vjXrviy++yP3334/dbsdisfDII49QUlIypd9dCDGznXT63KmyatUqvX379lH7cnUq2P5QjMN9IXwuO3XFnpwacZKrPzMhxNQ40fS50uVyEsFInCPHwuQ5bNQW5VaYCyFEJgn0EwjFEhzqDeG0Wagr8WCxSJgLIXKXBPpxROJJWnpC2CyKhpI8bDK5lhAix0lKTSCeMGjpMUevNJTkYbfKj0kIkfskqcZIJA0O9g6RNDQNJR6c8og4IcQMIYGewTA0Lb0hogmDumIPboeM6hRCzBwS6CmG1hzqC7Go0s+t117C2pXLJz197lQ6fPgw+fn5PPDAA9NWByHEzCBNUMz5zNuOhQlG4rjdbv6w07yjczLT5061u+++m2uvvXZaPlsIMbPM+Ra61pr2gQjHQjEqfKPnVjnZ9LmPPvooYM7lctlll3HTTTexePHirEyfC/Dkk0/S0NBAU1PTFP4EhBCzxaRa6Eqpa4CvYz4k+jta6/vHHL8d+CegLbXrIa31d86kYlu+v4muQwfO5BTjlNXNZ8Ptd47a1z0YpWcwSkm+Mz3ZVqaJps/dtm0b0WiU9evXc/XVVwOwY8cOdmdx+tzBwUG+9rWv8atf/Uq6W4QQk3LSQFdKWYGHgauAVmCbUuoprfWeMUX/W2t91xTUccr0DUXpGIhQ4HZQ6Xed9C7Q4elzn3jiCQAGBgZ46623pmT63C9/+ct89rOfHTelrhBCHM9kWuhrgP1a6wMASqnHgRuBsYGeVWNb0tk2EI7TdiyM12Wnush93DAfO33ugw8+yMaNG0eVmYrpc1955RWeeOIJ/vzP/5z+/n4sFgsul4u77ppRvzOFEGfRZPrQq4AjGdutqX1jvVcptVMp9YRSqiYrtZsig9EEh/tCuFPzs1iOE+Zjp8/duHEj3/zmN4nH4wBTOn3uCy+8QEtLCy0tLfzZn/0ZX/ziFyXMhRAnlK1RLj8D/ktrHVVK/QnwA+DysYWUUncCdwLU1tZm6aNPTTiW5FDPEA6rhfpiD9Yx87Mcb/pcgI997GO0tLSwYsWKKZ8+VwghTtVJp89VSl0IfFlrvTG1/QUArfU/HKe8FejTWvtPdN7pmD43mkjydtcQSsGC0nwctpk/yEemzxVibjnT6XO3AQuVUg1KKQdwM/DUmA+ozNi8ARj/xONpFk8aHOwZQqNpKMmbFWEuhBCZTtrlorVOKKXuAp7BHLb4Xa31bqXUfcB2rfVTwP9TSt0AJIA+4PYprPMpSxrmZFuJpGZ+SR4umZ9FCDELTaoPXWv9NPD0mH1fylj/AvCFbFRIa53Vh0gMz88SiRvUl3jwOGfPzbHT9bQpIURuyql+B5fLRW9vb9aCSmvNkWMhhqIJaorceF32rJw3F2it6e3tPeHQRyHE3JJTzdXq6mpaW1vp7u7OyvmOhWIMRZMUeOy0B220Z+WsucPlcqVvZhJCiJwKdLvdTkNDQ1bO9cAzb/LQllY+c/k5fO6iRVk5pxBC5LKc6nLJlu++eJCHtuznljW13H3VudNdHSGEOCtmXaA/uaON+/5vD9c0VfC37z4vqxdYhRAil82qQH/uzS4+/+M3uHB+Mf928/Jxd4EKIcRsNmsC/feHj/HJf/89iyq8bLptpYw1F0LMObMi0N/qDHLH97dR7nPy/Y+smVXDE4UQYrJmfKC39Ye57buvYrda+NFH1074kAohhJgLZnSg9w3FuO2xVxiMJvjhHWuoKfJMd5WEEGLazNhAH4om+Mj3t9F6LMxjH15NY6VvuqskhBDTKqduLJqsWMLgE//+GrvaBnj0j1eypqFouqskhBDTbsa10A1D87kfv8ELb/Vw/x8t5col5dNdJSGEyAkzLtAf3Lyfn71xlHuvXcz7VuX0k+6EEOKsmnFdLresqSHfZeOO9fXTXRUhhMgpMy7Qy3wuPnpxdibwEkKI2WTGdbkIIYSYmAS6EELMEhLoQggxS0igCyHELDGpQFdKXaOUelMptV8pde8Jyr1XKaWVUquyV0UhhBCTcdJRLkopK/AwcBXQCmxTSj2ltd4zppwX+FPglamoqBBCnDatIdIP8Qigze2TLgFtTLLsmOXJyhTNB29F1r/mZIYtrgH2a60PACilHgduBPaMKfdV4GvAPVmtoRBCTMQwINQLQ90w1AWDw8suc99gV8b+bjDi013jEdf/C6z+aNZPO5lArwKOZGy3AmszCyilVgA1WuufK6WOG+hKqTuBOwFqa2tPvbZCiBMzDDO8Aq0w0AaRAbC7M155qaUnY58HbE7Ihcc1JhMQ6hkTxmNDOrUM9Zgt6LEsdsgvg7xSyC+H8vNS62Xm90WlvutklpaRn8uk35N636h9jN4umZpnHZ/xjUVKKQvwL8DtJyurtd4EbAJYtWqVPtPPFjkkmQAjMX7/hCExwb7JlJtsmVwIpqmgNYT6RsI60AYDrRA4Onr9tFqiKiPkPeDwTBz84/aN/QVxnPLJ2CRa0V3m92OCaLC5IK8M8kvBXwNVK1LbZSNhPXzcVTB7/x84ickEehuQOWlKdWrfMC9wHvBc6oHMFcBTSqkbtNbbs1VRkQPiEeg/BH0Hxr/6j4BOTncNTU4fuAtHXp6i1HrRxNvuQnAXgGWaH1sYGRgT1G2p7eEAPwqJ8Oj3WOzgqwRfNdSsAV8V+KtTyyoz3BJRiIcgHob4UGoZztgXOvG+8DHz80eVG5q4dXwq7HlmAOeVQfECqF03QUCntp3eORvSp2Iygb4NWKiUasAM8puBW4cPaq0HgJLhbaXUc8DnJcxnqFgIjh2cILQPmiGT2Xpy+aFoAVStgvNuAkfemJNN0NLSE/3DbKJykykz0b4kRAIQ7jODKNQH/YdT2/0Tn2eYy3/i0B+1r8DcdvrBMonBYrGh8eE8qqXdBrHg6PcoC+RXmMFcsRQWXTsS1L5qc5lXNrnPzzatIRmfxC+FkPn/lNU2vkU97v8XcaZOGuha64RS6i7gGcAKfFdrvVspdR+wXWv91FRXUmRZNDhxYPcdgGD76LKeYvOKfN1F5jLz5Zlh89AbhjnSIXxs5BVKBf/wL4DhfaE+6N1vbkcGjn9OZTFbwWND3+aCYMdIazvSP/69eWVmKBefA/MvGx3WvnngrTSDMBcpBTaH+XIXTHdtRIrSE7aYpt6qVav09u3SiJ8y4WMjIT32NdQ9umx+eUZQN4ysFzbIX1Ywrw9EBka3+jN/CYQyfhkM74uHR1rXY1vVviozsG3y/Ftx6pRSr2mtJ7zXJ0d//YuTig7CYKf56j8yPrTDfaPLe+eZ/ZSLrh3dyi5sAGf+9HyHmcJqg7xi8yVEDpNAzyXDQ7aCHebV/+HATr9S+4Kd5kWpUZR59b+oAZbcOCa0681RC0KIWU0CfappbfZZjw3mUaHdBYMdMNTDhBftnH7zIpK3AuZdYHaR5JeZ/6TPLzNHNRTWyz/hhZjjJNBPl2GYFxAzAzmzVR3MCO+xQ80gdfND+UggV60wAzu/LLW/fOS43X32v58QYsaRQD9Vg92w40fw2vfM4XBjuQtHgrhm7eiA9mYEtatgeoabCSFmLQn0ydAaDv8Otj0Ge35q3olX/w646P+ZIxbSXSBl0u0hhBglYSSIJqOEE2GiySiRRIRiVzEFruyPIJNAP5FIAHb+N2z/LnTtMfuyV38UVt0BpYumu3ZCiNMUN+JEEpF0wA6vZ4ZuJDnxvsm8L10mGSExwZQYf73ur3n/ovdn/XtJoE+kfSdsfwx2/tgcTVK5HG54EM57r9zdJkQO01oTiAU4EjxCa7DVXA62prcDsQCRRITkaU5T4bQ6cVqduGwuXFbXqGWePS+97bQ5xx3P3N9U3JTlb26SQB8WD8PuJ55gGjMAACAASURBVM0gb90GNrcZ4KvvgKqV0107IURKwkjQMdQxKqiHl63BVoLx0VMolLhLqPHWsKp8FQWugnTAOq1O3Db3qIA+URA7rU4sKreve0mg975tdqm8/h/mHX7FC+Ga++H8m80LnEKIs24oPjQqqDNb2u2D7ST0SDeGzWKjOr+aam8155eeT423hmpvNTXeGqryq/DY5849GHMz0JMJePNpM8gPbAGLDRa/0+wfr3+HzOomxBQztEF3qHt8K3vQbGX3RUbf6ex3+qnOr6apuImN9RvN0M43Q7vMU4Z1umfKzBFzK9ADR+G1H8Dvf2COIfdVw4a/ghUfmpLHQQkxlyWMBEcHj9ISaOFI8Mio4G4bbCOajKbLWpSFCk8FNd4aNtRsSLewh5c+h28av8nMMfsD3TDg4HPmkMM3f2HO4XzOFeYjoBZenbuz2QkxA2it6Qx1cihwaNyrNdg6qmvEbXNT7a2m3lfPO6reMSq05+XNw261T+M3mR1mb5qF+sx+8e3fg763zWlgL7oLVn7EnO9ECDFp/ZF+WgIt40L7cPAw4Yw7oZ1WJ7W+WhYWLuSK2iuo89VR76+nxltDsasYJd2ZU2p2BbrW0LrdHKmy638hGYWadXDZveaEVXLTjxDHFYqHzKAOHuLQwEhotwRaCMQC6XJWZaUqv4o6Xx2rK1ZT76unzl9HnbeO8rzynB8JMpvNjkCPDsIffmwGeccfwOE1+8VX3QHlUzPeU4iZKJ6Mc2TwSDqwWwItHA4e5tDAIbrCXaPKlnvKqffVc039NdT6as3g9tVR5a3CbpHukVw0swO9q9nsG3/jcfPxXeVL4Z3/CkvfZz6DUIg5JhQP0RfpozfSS2+4N92/3RJo4dDAIY4OHcXIeBZoobOQWl8t6+atSwd2na+OGm/NnBruN1vMvEBPRKH5Z2aQH34JrE5oeo855LB6tQw5FLOK1ppgPEhv2Azo3kivGdip9d7w6O3wBDN7um1u6n31nFdyHtfPvz4d2nW+OvxO/zR8q9lDa40xNIQRCJBMvYxgkGQgiBEYIBkIkgwGMAYCJIPBdLmST30S3zXXZL0+My/Qf/tP5quwAa76Kiz/oDxJRswoSSNJf7R/wkBOb2esx434uHMoFIWuQopcRRS7i1laupRiVzHF7uJRy1JPKaXuUrkYeRxaa3Q0agZxIGAGcXB8OCcDAxgThXMwaI6kOwGL14vV68Xi82H1erHX1mDJm5qnhE0q0JVS1wBfx3xI9He01vePOf4J4NNAEhgE7tRa78lyXU0rPgy1F8L8DTL9rMgJ0WSUQDTAQHSAQCxAIBYwA3tMOA8v+6P9o7o9htksNjOgU4F8TsE5owI681ihs1BupjkOIxYj0dVNoquTRFcXic5O4l1dJLq6Sfb3Z4RzEGNgAB0f/wszk3K5sPp8WHxerF4fttJSHAsWmCHt92H1+rD6UoHt85kB7vebx/PzUdaz9+d00odEK6WswD7gKqAV2AbckhnYSimf1jqQWr8B+JTW+oT/npCHRItckjASBGPBdChnhvO4fdFAejkQGxh1g8xYbps7HcRF7qLR4TymNe1z+KQlfQI6mSTR25sK6650YMc7O0f2dXaS7O8f917lcGArLcVaVDRBEPvNpdeLNb3uw+o3w9nicEzDtz2+M31I9Bpgv9b6QOpkjwM3AulAHw7zlDwmfI6aEFNv+KLghEE8QRgPL4fGPaN1NI/Ng8/pw+fw4Xf6qfPVpdczl+l1p49iV7FcWJwErTVGIGCGc1cXic6udGAPt6wTnZ0kenogOWaWRIsFW3ExtrIy7FVVuC9Ybq6Xl2MrK8NWVo6trBRrQcGc+GU5mUCvAo5kbLcCa8cWUkp9GrgbcACXT3QipdSdwJ0AtbW1p1pXIcYJxUPs6NrBy+0v83L7y+zt23vcsnaLHb/Tj99hBm65p5xzC89NB3FmYA9v+x3mutzFOJ7WGhIJdDKJTiTM9fQrCYl4+pgRCIwO566ukQDv6kJHIuPOb/H7sZeVYisrx7lggRnQ5WXYy8qwDQd2cTHKNvMuBU6VrP0ktNYPAw8rpW4F/gr48ARlNgGbwOxyydZni7kjYSTY1bOLl9tf5pX2V3i9+3USRgK7xc7ysuV8avmnqPBUjG85O324rK5Z2UpLt3B7ekj09JLo6SaZWk8GAuhEHBJmsJoBm7mdgHgi41hGMI8rm4T4SEiPay1PknI6sZWXYy8rw33eeSPhXFaa0bIuw+JyZfknNftNJtDbgJqM7erUvuN5HPjmmVRKiGFaa97ufzsd4Ns6tzEUH0KhWFy0mA81foh1leu4oPwC3LbZ8zDt4eFwZjAPB3WPGda9vSS6e8z+5J4ekj09E1/Ys9ux+nwoux1ltZotWZsNZbOZF+rsNpTV3LZ43Oax1DY2K8qWep/dBtax26nz2KwTvC+1nfE+S14e9nKzZW3xemflL9ZcMJlA3wYsVEo1YAb5zcCtmQWUUgu11m+lNq8H3kKI09Qx1JHuQnml/RV6wj0A1HhruK7hOtZVrmNNxZopeSbjVDPC4VQwm690OPf0kOjtIZkR1BN1Qwz3GVtLSrCVlJhdEaXmurXYXNpKS7AVF2Px+yU4c0AybhAKxogMxgkFY4SDMcrrfRRWZP/pZycNdK11Qil1F/AM5rDF72qtdyul7gO2a62fAu5SSl0JxIFjTNDdIsTxDEQH2NaxLR3gLYEWAIpcRaytXMu6ynWsrVxLVX7V9Fb0BIxwmHh7B4mOdnPZ1TmqFW12g/RiDE1w8VUprIWF5sW90hLcdbXYhsO5ZDi8S831goKzOgxuNtJaYyQTJBPmy0gkSCbiGesTbScwUvsS8TjRoSiRwQjRUJRoOEY0FCUejhGNxIhHYiRiceLRGMl4nGQiiTmiOwnaQJPk/CvfyRUfeWfWv9uk+tC11k8DT4/Z96WM9T/Ncr3ELBZJRHi9+3VePmq2wpv7mjG0gdvmZlX5Kt537vtYN28dCwsW5kQL04jFzLHM7e0kOjqIt3cQ72gn0d5BvKODRHs7yYGBce+z+P1mKBcX4246D2tJcSqYzaBOt6qLClF2ueh6qoxkknAwQGQwSDgQIBwc/xp7LB6NYiTHP7Q5OxQoK0pZURYbFqsVq9WGzW3Hardhs9uxORzYHHaqFhdNSQ3k8rCYckkjSXNfc7obZUfnDmJGDJuysax0GZ9Y9gnWVq5lacnSsz6aRCcSJLq7R7Wu4x2j15M9PePeZ/H7sVdUYK+owL38fOwVldgrK7ANL8vLsThlds/JMpJJM3zHhnIgQHgwSGTUtrkenehfOyl2pwtXvheHx4vdkYensJa8YhfasJNMQCIOiZgiEdPEoqANCwoLKCtgBWUBrDhcDpx5Tlx5Tlz5Ltz5LtxeF26fG4/PRb7fg6fATV6hecximd4GiAS6yDqtNS2BFl5pf4WX21/m1Y5XCcbMB/eeW3guH1j8AdZVrmNl+Ury7NnvR0zXwzBI9vYS7+g4fuu6q2vcrdsWjwdbZSX2igqcixdlhHUF9tR+i0fGl0+GkUzS/tab9LYdGWk1j21FB4NEhgaPew6b04nb60u/vCVl2Bx5WKwelMWNYThJJp0kYnZiEQeRISuhoEE8miQ+5rQ2uwW310FeoR23z4Hb68DjteP2muvu/Ix1rx2rbWbdjS6BLs6I1pqh+BDHosd4vev1dIh3hjoBmJc3j6vqrkpfyCx2Z3/encSxY0Sbm4k0NxPdt49421EzxDs7YczoD+V0Yq+owFZZSd66ddgqK8YFtiU/Pye6emaq0EA/B19/jYM7ttOy8/ejWtI2pxN3fiqcfT78ZRW48r24vT4cnnwsFg/gxDBcJOIO4lE74UFNaCDK0ECMvu4o8cj44ZI2h4U8v5O8AidlpQ5z3e8kr8CBx+8kz2/uc7hnd+TN7m8nJsXQBoPxwZG7KGMBgrHgqO3jrQdjQZJ65C+Y3+lnbcVa1lau5cLKC6n2VmctHLVhEG9tJdK8l8jeZqLNe4k0N5Po7EyXsZWXY6+pxr18Ob4xrWpbZeWcuWPwbDKMJJ1v7+fAju20vL6djrfNQW55BYWcs/pC6s9fibe4jmTCSTQMoYEYQ/1RhlIhPXA4ylB/lFg6qOOpF1jtFjOMC5yUVOdT11SMJ7U9vN/jd+JwWeXPFQn0WSNpJM1QPkkAT7Q+GB+ccLKoYVZlHXcnZY23Jr09fGxx0WIWFy3OyhNrjFiM2P79Zng3N5sBvvdNjMHUv6GtVpzzG/CsXYNrcSOuxsU4Fy/GVlh4xp8tTi4cDNCyc4fZCn/9NcLBAEpZqFy4iPUf+BBVi5YzFMin5Q/HeOF/eolF9o96v9VmIa/AbDUXzcujprEoHdKejNa1w22ToD4FEugzTCge4s1jb7Kndw97evfQ3NdMx2AHg/FB9Amm0LFZbKPCt8hVRL2vflRQj70FfnjdY/NM6V+qZCBApHkv0b3N6QCPvv02JMzRCMrjwbVoEf4b3oVz8WJcjUtwLjxH7iQ8i7Rh0NVygIM7tnPg9e10vLUPrQ3cXh/1y1fSsHwlBZWLaX87SsvOHn7/qza0Bo/PwTkry6hYUEB+gTPdunZ6JKinggR6DgvGguzt25sO7ubeZg4OHEwHd7GrmCXFS1hVvuq4YTy87ra5p/0vkNaaRHs7kb2pVnez2W0Sbxu58dhaWoJrcSP5l16abnU76upQMlXyWRcNDXFo545UV8prDPUfA6BiwULWvfcD1C1bSdIo5fCuPl57poeBbnO+vuLqfFZeW0/90hLK6ryoaR75MZdIoOeIgehAOrSHA/xQ4FD6eJmnjCXFS7im/hoaixtZUrwkpx9coONxogcPpi5W7iWydy/R5uaR8dpK4aivx33+Mgo+8AFcjYtxLV6MrbR0eis+h2mt6TlyiIM7tnNwx3ba3tyDNgyceXnUL1tBwwWrqFy4jJ7WJC07e/jFo11EQ0ex2BTViwo5/4oa6peV4C2SfzlNFwn0adAX6aO5t5nmvuZ010nb4EgrdV7ePBqLG7lhwQ00FjXSWNxIibtkGms8QmuNjsUwQiF0KIQRDmOEQhhDQ0QPHEi3uqNvvYWOxQBzZInz3HPxXn01riWNZrfJuediyZu6IYticmLhEId2vUHLjtc48Pp2BnvNMfel9fNZc+NNNCxfhdtXw6Hdx9i3vYfn/3sX2tC4vXYalpfSsLSE6sZCHC6Jklxw0gdcTJW58oCL7lD3qOBu7mumY6gjfbzGW0NjkdnibixuZEnRkqzMUaKTyXTYpoM3HMYYCmGEQ+b+cBgjlArkcBgjnCo7al8YIzSEDoXT5zvRI7esBQWp0DYvVLoaG3HU18sUpzlCa03f0dZ0K7y1eTdGMoHD7aZu2QU0LF9F3dILGOy3cXBnLy07e+jvDAFQXJVH/dIS6peVUF7vk66UaXKmD7gQk6C1pjPUmQ7tPb17aO5tpjvcDZjPgKzz1XFB2QU0FTfRWNTI4uLF+By+0/q8WGsrQ1tfYuill4gfPZoK45Eg1tHjP0VnIsrlwuJ2Y/F4sHjcKLcHi8eD3e/P2Jc67vaYZfPMpUrtc9TVYisvz9luoLkqHo1wZPcfOPi6GeIDXeYwz+LqWlZcdwPzL1hFce1C2t4M0LKzh1f+r5loKIHFqqhaVMjSy6qpX1qMr2T2zGY5W0mgn6becC+/7/r9qD7vvkgfABZlYb5/Pusq16X7uxcXLT6juyKTg4OEXn2VoRe3MrR1K7FDZv+6raIC5znnmDfEpEJWud1m6KaCODN0M/dZPB4zuN0umfBpBtOGQWRokKH+Ywz1HyM00J9edh9u4cjunSTjcWxOJ3VLl7P6hvfSsHwVmnxadvby2rM9tL/1MoahceXbaVhmtsJrlhRJV8oMI39ap6BloIUtR7aw+fBm3uh+A43GpmwsKFjAJdWXpLtOzi0894wfPaaTSSK7djG4dStDW18i/MYbkEig3G48a1ZT+MFbyVu/Hsf8+dIinoW01kRDQ+lwHhvUmftCA/0YEzxswmq34y+r4PyrrqPhglXMO3cJPa1hWnb28H8PH+BYh9mVUliZx/KraqhfWkL5fP+0z0ciTp8E+gkY2mBXzy42H97MliNbODBwAIDGokY+ef4nWV+1nkVFi3BaszMJU7ytLR3gQy+/jJEaEeJqaqL4jjvIu+gi3CsuyLmH1orJi0XCZhD39zM0MLKcKKiTEzy0wmK14vEX4PEXkFdQSFn9/PR6XkHhqHWH20M8kuTwnj72v9bDb37wKpGhOBaLYt65BTS9o4r6ZSX4S6UrZbaQQB8jlozxSvsrbD6ymeePPE93uBursrKqYhXvX/R+NtRsYF7+vKx8VnJwyOxG2ZrqRmlpAczb171XXEHe+ovIu/BCbEVTM9XmbKK1RmsDbRgYyWRqaWAYqXUjiU4aGIaBNpIYydTSGHmPYRjmxeThfcPvTY6cI7P82GPm0tyXjMcIDQyMBHUqvOPRCR5aoRQen588fwGegkKK5lUfN6RdefnHHZOvtSbYG6HzYIA9Lx6ls2WArkNBjKTGmWej7rxi6peWUNtUjHOWz2kyV8mfKuYY8BfaXmDL4S282PYioUQIj83D+qr1XF57Oe+oegd+p/+MP0cnk0T27DED/MWthF5/3exGcbnMbpRbbja7URYsyPluFG0YDB7rY6Crg0B3FwPdncSj0ZFwTCZTwTk6PIePmQGbHBWww/uN5MixkZBNZpw3Fa7J0cdyjcvrI89fQF5BAZXnLCKvoACP3wzm4fDOKyjE7fNhsZz6NYxoKE5XS5DOlgE6DwbobAkQDo7MgVJW6zXHhi8toWK+D4tVbs6a7eZsoLcPtpv94Uc281rHayR0ghJ3CdfNv44NNRtYW7k2K10p8fZ2hrZuZXDrVkIv/S59Y41zSSPFH7mdvPXrca9YkXPdKFprQgP9DHR1EujuZKCrk4HuTjO8uzoIdHePe1CANfWsSovFisVqvpTFktq2pLYn3m+xWLE5nal1S6qcZcJzKesJjlks484xsky9x2JJlxu1VJZU/TOWY847+vwTH1MWC1ar+YCDbEkmDXpbB9PB3XkwkB5OCFBY4aGuqZjyBh/lDX6KqvKwSoDPOXMm0LXW7Du2j81HNrPl8Baa+5oBaPA38OGmD7OhdgNLS5ae8cRSxtAQQ9u2mf3gW7cSO2D2u9tKS8nfsIG89evJu+hCbMXZn0b2VGitiQwNEkgF9UBX56jwDnR3kYiNHvro9vnxl5VT1nAOC9eux19ajr+0DF9ZBb6SUmw59ktppkp3naSCu/NggO4jQZJxc/y/22unvMHPorUVlNf7KKv34vTIE4/ELA/0hJFgR9eO9EXNtsE2FIrzS8/n7pV3s6FmA/X++jP6DG0YRPY0p/vBQzt2QDyOcjrxrF5NwfveR976i3AuPPuPU4uFQ6mWdReBro7R691dxMKhUeWdeXn4SysomldNw/KV+MvK8ZWWp5ZlOFxy8WwqRMMJuobDuyVA58GBUV0npTVezrukymx91/vwFrtyvktOTI9ZF+iheIiXjr7E5sOb+W3bbxmIDuCwOLhw3oV8fOnHubTm0qzcRh967TWO/cd/MvS735E8Zk5a5GxspOi2D5G/fj3ulSuz/ggyrTXJeJx4LEoiGiUejRCPRgn1HxvpEslocUcGg6Peb3e60uFcvWRpet1fVoGvtAxXXn5W6yvGSyYN+tqG6Dw40u89PHwQoKDcQ21TMeX1PsobfBRX50vXiZi0SQW6Uuoa4OuAFfiO1vr+McfvBj4GJIBu4A6t9aFxJ5oiPeEenj/yPJuPbObloy8TM2L4nX4urb6UDTUbuGjeRWc8LnyY1pq+H/yArn96AGtBAfmXXELexevxrFuHpbCAeCpoB/p6Uuup8I2Z+xPD+2IjgTwczscvN3IefaJ5y+12s0VdWkbFgoXp1rW/tBxfWTlur09admeR1ppgXyQd3F0HA3QfDpJIdZ248u2UN/hYuLqc8gYfZXU+XHnSdSJO30nnclFKWYF9wFVAK7ANuEVrvSejzAbgFa11SCn1SeAyrfUHTnTeM53LpWWgJd0fPnyTT1V+FRuqL+OyeZdyXkEjJDWJWIxEPEYiFiMZj5GIxc1lPEYiHicRi5KMxUnEYyTj8XTZdPl4nOTwOaIRQm/tJ9Z/DLxeVFERiXgsHcz6BHOcHI/N6cTudGF3OrE5MtadTuwO58h6qpwtvW+knMdXgL+0jLyCQplmdhK01hgJTTJhpF4j60bSIBlPbScNknHDLJtMlY0bGMnjvDdjPToUp/NQkHDAnKDMarNQWptPWarlXV7vx1ciXSfi1J3pXC5rgP1a6wOpkz0O3AikA11rvSWj/MvAH59+dU/s8f/9Os2//hXxeAxrUrEYBxewEJthwUgkSMZfxPzv9NkcTmx2O1aHw1zaHViVInn4CGoohLeuDvc5C7DZHdhdruMHciqUh0N7eJ/N4cTucmGzO+bEX+ixAZqIG6NCMHM7OdF6XJNMJM3wTO1LJAyMeOb5dEbgjg/bzMA1ktmdkM5iUVhsCqvNgtVmwWJTOFw2ahuLUqNOfBRX5c+4Bw6LmWcygV4FHMnYbgXWnqD8R4FfTHRAKXUncCdAbW3tJKs4mtVmw+p0UFpcRbmvgnyPH5vdgdVhN5d2M4RtDgc2x8i2Gc7Dx5xYh8vYHSPrDgcW6/gnqQy99BJtn70bbRhUPfBP5F966WnVfabQWhOPJomFk0TDcWKhBNFwgmgoQSy1jIZH1mPhONFQwgzWcYFshmhWKLOla7NbsNgsWFMharNb0mFqtVtwuG3mMbsFq3WknCUjcNPlxwRxer/VgtWuzPdYh8+tsFhHPsdqNY/LrfIiV2T1oqhS6o+BVcCEiae13gRsArPL5XQ+4303fBpu+PRp1/FUaK3p+9736XrgAZwL5lP90EM46urMY4YmFIyhlEJZQCmFxaJQltS2RWFRalqmGB0O5HEBHIqPDuZwYlRYZ25r48R/PDa7BYfHhtNtw+mx4cq3Y3NYR8IuFZYj4TsmeG0Kq906EqijjmVs20eOWyxqTvyLRojTNZlAbwNqMrarU/tGUUpdCfwlcKnW+tTmbs1BRihE+1/9NYGnn8a7cSPz/v7v0g9kGBqI8otv/YHOg4FJnWs45IcDPr2dCihlGf5lQMa6Sv+yOO52al8yMTq8Y+EEJ5vm3ua0psPY6bbh8TsoKPekt0fC2j5m25ZqAUv3gRC5ZjKBvg1YqJRqwAzym4FbMwsopS4AHgWu0Vp3Zb2WZ1nsyBFa7/oM0X37KL37boo//rF0y7D7cJCfP7KTaDjBhe9ZgN1pNecRMcAwNNrQqW2NYZgt+eF9o7YNjaEx5xfRY/YbpM8x8bZGJ0Y+x2q3kF/gxDEvD6fbng7ddDhnBHE6kGUonBCzzkkDXWudUErdBTyDOWzxu1rr3Uqp+4DtWuungH8C8oEfp4LvsNb6hims95QZfHErbZ/7HGhNzaZHyX/HO9LH3t7Rxa+/twdXnp333rOCkmrvNNZUCCFGm1Qfutb6aeDpMfu+lLF+ZZbrddZprel77DG6/uVfcZ5zDtUPPYgjdeFWa81rvzjEK08doLzBx7WfWEqeP7s3DQkhxJmadXeKng4jFOLoX/4lwV/8Eu+11zDv7/4Oi8e8ESkRT7LlR3vZ92on564pZ8OHFmOzy9N9hBC5Z84HeuzwYbO/fP9+yj7/OYo++tF0f3koEOPpb+6k82CAtTfOZ+U1dTLKQgiRs+Z0oA++8AJtn/s8KEXNpk3kX7w+faynNcjPH95JZCjONX9yHgsuKJvGmgohxMnNyUDXWtO76dt0/9u/4Tz3XLO/vGZkZOaB17v51ff24HTb+KPPr6S0Vi5+CiFy35wLdGNoiKNf+CLBZ5/Fd/31VH71vnR/udaaHc8e5ndPvk1ZrZfrPrVMLn4KIWaMORXosZYWWj/zGaJvH6DsL/6Cots/nO4TT8YNnvuPvex9uYNzVpVxxW2N2Bxy8VMIMXPMmUAffP552j5/D8pqpfax75B34YXpY6FAjF8++gfa3x5gzbsaWHVdvVz8FELMOLM+0LVh0LtpE91f/wbOxYupfvBBHNVV6eO9bYP8/OGdhIIxrv5YEwtXlU9jbYUQ4vTN6kBPDg7R/oV7Cf7q1/je9S4q7/sKFvfIY9Radvbw7GO7sbusvOdzKyiv901jbYUQ4szM2kCPHjxI612fIdbSQvkX7qXwttvS3Shaa17/9RFe+t/9lNZ4ue6Ty8gvlIufQoiZbVYGenDLFo7e8+cou53axx4jb93I9O3JhMHz//kmzS+1s2BFKVfcvgS7XPwUQswCsyrQtWHQ881v0vPgQ7iWLKH6wW9grxrpLw8Pxvjlo7s4+lY/q66rZ807G6ZlvnIhhJgKsybQk4ODHP2Lexn8zW/w33gDFV/5ChaXK3287+gQP3/kDYb6Y1x1xxLOXVMxjbUVQojsmxWBHj1wgNZP30Xs8GHKv/hFCj/0x6OGHR7a1cuz39mF1WHl3Z+7gIoG/zTWVgghpsaMD/Tg5s1mf7nTSe33vkvemjXpY1prdm5uZesTb1FUlc/1n1qGt8h1grMJIcTMNWMDXRsGPQ8/Qs/DD+NqajL7y+fNSx9PJg1++/g+9rxwlIbzS7jyI0twuGbs1xVCiJOakQmXDAY5es+fM/jcc/jf/W4qvvw3o/rLI0NxfrnpD7S92c+Ka+pYd8N8ufgphJj1ZlygR/fvN8eXt7ZS/td/ReGtt47qLz/WMcTPH95J8FiEK29vZNG6ymmsrRBCnD0zLtCHtm4lGQxS9/3v4Vm1atSxI3v6+OW3d2G1Kd792RVULpCLn0KIuWNSj35XSl2jlHpTKbVfKXXvBMcvUUr9XimVUErdlP1qjii87Tbm/9/PxoX5H55r5WcPvYG3yMlN966SMBdCzDknbaErpazAw8BVQCuwIxOkVAAABKhJREFUTSn1lNZ6T0axw8DtwOenopJj6oOtsDC9bSQNXvift9j1fBv1y0q46g65+CmEmJsmk3xrgP1a6wMASqnHgRuBdKBrrVtSx4wpqONxRYbiPPPtXbTuPcYFV9Wy7j0LsMjFTyHEHDWZQK8CjmRstwJrj1P2hJRSdwJ3AtTW1p7OKdL6O0P8/JGdBHrCXH7bYhovmnfyNwkhxCx2VvsmtNabgE0Aq1at0qd7nta9ffxy0y6UUtz4Zxcwb2FB1uoohBAz1WQCvQ2oydiuTu2bFnt/186WH+3FX+7h+k8tw1/qPvmbhBBiDphMoG8DFiqlGjCD/Gbg1imt1Qn4yzzULyvhig834nDLxU8hhBh20kTUWieUUncBzwBW4Lta691KqfuA7Vrrp5RSq4GfAIXAu5RSX9FaN01FhSsX+KlcsHQqTi2EEDPapJq4WuungafH7PtSxvo2zK4YIYQQ02RSNxYJIYTIfRLoQggxS0igCyHELCGBLoQQs4QEuhBCzBIS6EIIMUtIoAshxCyhtD7tKVXO7IOV6gYOnebbS4CeLFZnppOfx2jy8xghP4vRZsPPo07r/7+9+3mxqo7DOP5+cJIag2rRxpkBZyHJEIQhYQku0oVh1NagFq37oRGE9TeE1CKE0NwkuhhdSES6sLWUP6B0DIYpnDElN1q0UelpcW44MxYacvncc+7zWt1z7l08fLjn4ZzvuT/85L89UVboD0LS97Y33PuVwyHzWCrzuCOzWKrr88iSS0RER6TQIyI6oq2F/nl1gAGTeSyVedyRWSzV6Xm0cg09IiLu1tYz9IiIWCaFHhHREa0rdEnbJP0kaVbS7uo8VSRNSPpW0gVJ5yXtrM40CCStkHRW0lfVWapJelzStKSLkmYkPV+dqYqk93rHyY+SDkl6uDpTP7Sq0CWtAD4DXgKmgNckTdWmKnMbeN/2FLAReGuIZ7HYTmCmOsSA+BT4xvY64BmGdC6SxoB3gQ22n6b557Udtan6o1WFDjwHzNqes30TOAy8WpyphO0rts/0Hv9Bc7CO1aaqJWkc2A7sq85STdJjwGZgP4Dtm7av16YqNQI8ImkEGAV+Lc7TF20r9DFgftH2AkNeYgCS1gDrgVO1Scp9AnwA/FUdZABMAteAA70lqH2SVlWHqmD7MvAxcAm4AtywfaI2VX+0rdBjGUmPAkeAXbZ/r85TRdLLwG+2T1dnGRAjwLPAXtvrgT+BobznJOkJmiv5SWA1sErS67Wp+qNthX4ZmFi0Pd7bN5QkPURT5gdtH63OU2wT8IqkX2iW4l6U9GVtpFILwILtf67apmkKfhhtBX62fc32LeAo8EJxpr5oW6F/B6yVNClpJc2NjWPFmUpIEs366IztPdV5qtn+0Pa47TU074uTtjt5FnY/bF8F5iU91du1BbhQGKnSJWCjpNHecbOFjt4gHqkO8H/Yvi3pbeA4zZ3qL2yfL45VZRPwBvCDpHO9fR/Z/rowUwyWd4CDvZOfOeDN4jwlbJ+SNA2cofl02Fk6+hMA+ep/RERHtG3JJSIi/kMKPSKiI1LoEREdkUKPiOiIFHpEREek0CMiOiKFHhHREX8D+c+0BRKVffQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LXXPglzbPuo",
        "outputId": "88e2173b-f39d-4a69-c154-db51011b4a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "fig = fig.get_figure()\n",
        "fig.savefig('Q1.pdf')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-8e006b86c498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Q1.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'savefig'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JAoCyuRT2Md",
        "outputId": "e5d76d4c-037a-4e19-e946-b3a19a8e2688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I5JJL1sXf0X",
        "outputId": "283115ee-a0ed-4c4d-cab9-11084463e7bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "data_augmentation = False\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "def build_model(activa):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                  input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation(activa))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation(activa))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation(activa))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation(activa))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation(activa))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  # Let's train the model using RMSprop\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def train_cnn(model, epochs):\n",
        "  if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "  else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "    \n",
        "    # # Save model and weights\n",
        "    # if not os.path.isdir(save_dir):\n",
        "    #     os.makedirs(save_dir)\n",
        "    # model_path = os.path.join(save_dir, model_name)\n",
        "    # model.save(model_path)\n",
        "    # print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "    # Score trained model.\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Accuracy:', scores[1])\n",
        "  return scores[1]\n",
        "    # cnn_performance.append(scores[1])\n",
        "    # print('Test loss:', scores[0])\n",
        "    # print('Test accuracy:', scores[1])\n",
        "\n",
        "act_functions =['relu', 'sigmoid']\n",
        "models_dict ={}\n",
        "for act_function in act_functions:\n",
        "  models_dict.update({act_function:build_model(act_function)})\n",
        "\n",
        "act_performance_dict ={}\n",
        "for item in models_dict.items():\n",
        "  act_function, model = item\n",
        "  temp_performance =[]\n",
        "  for i in range(10):\n",
        "    print(\"validate epoch:{}\".format(i+1))\n",
        "    performance = train_cnn(model, i+1)\n",
        "    temp_performance.append(performance)\n",
        "  print(\"act_performance_dict\", act_performance_dict)\n",
        "  print(\"temp_performance\",temp_performance)\n",
        "  act_performance_dict.update({act_function:temp_performance})  \n",
        "\n",
        "print(act_performance_dict)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ae1c99fb3848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_augmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saved_models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'keras_cifar10_trained_model.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1loFbq_qY2Ke"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEdRyqUyXgWf"
      },
      "source": [
        "df = pd.DataFrame(performance_dict)\n",
        "fig = df.plot()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlS7ihm9Yypd"
      },
      "source": [
        "fig = fig.get_figure()\n",
        "fig.savefig('Q2.pdf')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTpf8uWKzlhB"
      },
      "source": [
        "<h1> why did some models perform better or worse than\n",
        "other models and are the results consistent with the theory?</h1>\n",
        "\n",
        "\n",
        "\n",
        "*   The CNN model has the best result since it could extract spatial info on animage, and build complex feature maps that help the classification. In short, better feature \n",
        "*   For the fully connected network, as the number of hidden layer increase, the performance decrease. This decrement in performance is result from the overfitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J08z5-u737nY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
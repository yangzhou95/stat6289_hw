{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcBhsBuULNZu",
        "outputId": "de8cc375-f58a-4cf3-a93b-1ff6b0b47b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "print(keras.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urwvurXWLDjp",
        "outputId": "71842168-d71d-4c2c-e9e3-ab9839436024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "data_augmentation = False\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "def build_model(activa):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                  input_shape=x_train.shape[1:]))\n",
        "  model.add(Activation(activa))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation(activa))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation(activa))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation(activa))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation(activa))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  # Let's train the model using RMSprop\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def train_cnn(model, epochs):\n",
        "  if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "  else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "    \n",
        "    # # Save model and weights\n",
        "    # if not os.path.isdir(save_dir):\n",
        "    #     os.makedirs(save_dir)\n",
        "    # model_path = os.path.join(save_dir, model_name)\n",
        "    # model.save(model_path)\n",
        "    # print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "    # Score trained model.\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Accuracy:', scores[1])\n",
        "  return scores[1]\n",
        "    # cnn_performance.append(scores[1])\n",
        "    # print('Test loss:', scores[0])\n",
        "    # print('Test accuracy:', scores[1])\n",
        "\n",
        "act_functions =['relu', 'sigmoid']\n",
        "models_dict ={}\n",
        "for act_function in act_functions:\n",
        "  models_dict.update({act_function:build_model(act_function)})\n",
        "\n",
        "act_performance_dict ={}\n",
        "for item in models_dict.items():\n",
        "  act_function, model = item\n",
        "  temp_performance =[]\n",
        "  for i in range(10):\n",
        "    print(\"validate epoch:{}\".format(i+1))\n",
        "    performance = train_cnn(model, i+1)\n",
        "    temp_performance.append(performance)\n",
        "  print(\"act_performance_dict\", act_performance_dict)\n",
        "  print(\"temp_performance\",temp_performance)\n",
        "  act_performance_dict.update({act_function:temp_performance})  \n",
        "\n",
        "print(act_performance_dict)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "validate epoch:1\n",
            "Not using data augmentation.\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8313 - accuracy: 0.3292 - val_loss: 1.5571 - val_accuracy: 0.4329\n",
            "Accuracy: 0.43290001153945923\n",
            "validate epoch:2\n",
            "Not using data augmentation.\n",
            "Epoch 1/2\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5127 - accuracy: 0.4500 - val_loss: 1.3755 - val_accuracy: 0.5058\n",
            "Epoch 2/2\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.3723 - accuracy: 0.5011 - val_loss: 1.2526 - val_accuracy: 0.5545\n",
            "Accuracy: 0.5544999837875366\n",
            "validate epoch:3\n",
            "Not using data augmentation.\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2793 - accuracy: 0.5434 - val_loss: 1.2062 - val_accuracy: 0.5661\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2057 - accuracy: 0.5700 - val_loss: 1.1014 - val_accuracy: 0.6097\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1369 - accuracy: 0.5998 - val_loss: 1.0525 - val_accuracy: 0.6280\n",
            "Accuracy: 0.628000020980835\n",
            "validate epoch:4\n",
            "Not using data augmentation.\n",
            "Epoch 1/4\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.0826 - accuracy: 0.6197 - val_loss: 0.9944 - val_accuracy: 0.6483\n",
            "Epoch 2/4\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.0377 - accuracy: 0.6374 - val_loss: 0.9928 - val_accuracy: 0.6539\n",
            "Epoch 3/4\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9969 - accuracy: 0.6511 - val_loss: 0.9541 - val_accuracy: 0.6675\n",
            "Epoch 4/4\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9600 - accuracy: 0.6643 - val_loss: 0.9065 - val_accuracy: 0.6825\n",
            "Accuracy: 0.6825000047683716\n",
            "validate epoch:5\n",
            "Not using data augmentation.\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.9316 - accuracy: 0.6765 - val_loss: 0.8782 - val_accuracy: 0.6924\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.9012 - accuracy: 0.6872 - val_loss: 0.8706 - val_accuracy: 0.6972\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8756 - accuracy: 0.6935 - val_loss: 0.8710 - val_accuracy: 0.7030\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8530 - accuracy: 0.7015 - val_loss: 0.8296 - val_accuracy: 0.7115\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8342 - accuracy: 0.7110 - val_loss: 0.7728 - val_accuracy: 0.7325\n",
            "Accuracy: 0.7325000166893005\n",
            "validate epoch:6\n",
            "Not using data augmentation.\n",
            "Epoch 1/6\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8135 - accuracy: 0.7185 - val_loss: 0.8083 - val_accuracy: 0.7184\n",
            "Epoch 2/6\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8028 - accuracy: 0.7227 - val_loss: 0.8041 - val_accuracy: 0.7273\n",
            "Epoch 3/6\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7853 - accuracy: 0.7297 - val_loss: 0.7537 - val_accuracy: 0.7429\n",
            "Epoch 4/6\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7769 - accuracy: 0.7342 - val_loss: 0.7506 - val_accuracy: 0.7430\n",
            "Epoch 5/6\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7669 - accuracy: 0.7373 - val_loss: 0.7374 - val_accuracy: 0.7468\n",
            "Epoch 6/6\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7575 - accuracy: 0.7394 - val_loss: 0.7196 - val_accuracy: 0.7576\n",
            "Accuracy: 0.7576000094413757\n",
            "validate epoch:7\n",
            "Not using data augmentation.\n",
            "Epoch 1/7\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7472 - accuracy: 0.7457 - val_loss: 0.7403 - val_accuracy: 0.7505\n",
            "Epoch 2/7\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7392 - accuracy: 0.7477 - val_loss: 0.7147 - val_accuracy: 0.7551\n",
            "Epoch 3/7\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7330 - accuracy: 0.7478 - val_loss: 0.6968 - val_accuracy: 0.7651\n",
            "Epoch 4/7\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7277 - accuracy: 0.7506 - val_loss: 0.7396 - val_accuracy: 0.7463\n",
            "Epoch 5/7\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7226 - accuracy: 0.7538 - val_loss: 0.7116 - val_accuracy: 0.7577\n",
            "Epoch 6/7\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7154 - accuracy: 0.7552 - val_loss: 0.6994 - val_accuracy: 0.7633\n",
            "Epoch 7/7\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7135 - accuracy: 0.7574 - val_loss: 0.7187 - val_accuracy: 0.7588\n",
            "Accuracy: 0.7588000297546387\n",
            "validate epoch:8\n",
            "Not using data augmentation.\n",
            "Epoch 1/8\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7063 - accuracy: 0.7598 - val_loss: 0.7135 - val_accuracy: 0.7531\n",
            "Epoch 2/8\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6987 - accuracy: 0.7620 - val_loss: 0.6915 - val_accuracy: 0.7676\n",
            "Epoch 3/8\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7005 - accuracy: 0.7627 - val_loss: 0.6965 - val_accuracy: 0.7635\n",
            "Epoch 4/8\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6931 - accuracy: 0.7617 - val_loss: 0.6845 - val_accuracy: 0.7662\n",
            "Epoch 5/8\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6884 - accuracy: 0.7656 - val_loss: 0.7239 - val_accuracy: 0.7573\n",
            "Epoch 6/8\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6864 - accuracy: 0.7660 - val_loss: 0.7153 - val_accuracy: 0.7690\n",
            "Epoch 7/8\n",
            "1556/1563 [============================>.] - ETA: 0s - loss: 0.6762 - accuracy: 0.7699Epoch 8/8\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6796 - accuracy: 0.7700 - val_loss: 0.6868 - val_accuracy: 0.7707\n",
            "Accuracy: 0.7706999778747559\n",
            "validate epoch:9\n",
            "Not using data augmentation.\n",
            "Epoch 1/9\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6740 - accuracy: 0.7720 - val_loss: 0.6842 - val_accuracy: 0.7794\n",
            "Epoch 2/9\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6723 - accuracy: 0.7734 - val_loss: 0.6751 - val_accuracy: 0.7781\n",
            "Epoch 3/9\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6696 - accuracy: 0.7738 - val_loss: 0.6910 - val_accuracy: 0.7700\n",
            "Epoch 4/9\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6643 - accuracy: 0.7767 - val_loss: 0.7014 - val_accuracy: 0.7635\n",
            "Epoch 5/9\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6622 - accuracy: 0.7753 - val_loss: 0.6855 - val_accuracy: 0.7695\n",
            "Epoch 6/9\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6567 - accuracy: 0.7786 - val_loss: 0.6900 - val_accuracy: 0.7692\n",
            "Epoch 7/9\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6611 - accuracy: 0.7774 - val_loss: 0.6905 - val_accuracy: 0.7707\n",
            "Epoch 8/9\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6598 - accuracy: 0.7773 - val_loss: 0.6859 - val_accuracy: 0.7740\n",
            "Epoch 9/9\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6592 - accuracy: 0.7780 - val_loss: 0.6691 - val_accuracy: 0.7804\n",
            "Accuracy: 0.7803999781608582\n",
            "validate epoch:10\n",
            "Not using data augmentation.\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6568 - accuracy: 0.7806 - val_loss: 0.7550 - val_accuracy: 0.7645\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6494 - accuracy: 0.7793 - val_loss: 0.7581 - val_accuracy: 0.7410\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6523 - accuracy: 0.7816 - val_loss: 0.6829 - val_accuracy: 0.7732\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6463 - accuracy: 0.7841 - val_loss: 0.6419 - val_accuracy: 0.7884\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6454 - accuracy: 0.7842 - val_loss: 0.6964 - val_accuracy: 0.7775\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6442 - accuracy: 0.7831 - val_loss: 0.6769 - val_accuracy: 0.7731\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6429 - accuracy: 0.7833 - val_loss: 0.6639 - val_accuracy: 0.7794\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6409 - accuracy: 0.7860 - val_loss: 0.6814 - val_accuracy: 0.7725\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6377 - accuracy: 0.7865 - val_loss: 0.6751 - val_accuracy: 0.7812\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6381 - accuracy: 0.7864 - val_loss: 0.6750 - val_accuracy: 0.7751\n",
            "Accuracy: 0.7750999927520752\n",
            "act_performance_dict {}\n",
            "temp_performance [0.43290001153945923, 0.5544999837875366, 0.628000020980835, 0.6825000047683716, 0.7325000166893005, 0.7576000094413757, 0.7588000297546387, 0.7706999778747559, 0.7803999781608582, 0.7750999927520752]\n",
            "validate epoch:1\n",
            "Not using data augmentation.\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3319 - accuracy: 0.0985 - val_loss: 2.3047 - val_accuracy: 0.1000\n",
            "Accuracy: 0.10000000149011612\n",
            "validate epoch:2\n",
            "Not using data augmentation.\n",
            "Epoch 1/2\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3072 - accuracy: 0.0979 - val_loss: 2.3053 - val_accuracy: 0.1000\n",
            "Epoch 2/2\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3066 - accuracy: 0.1001 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
            "Accuracy: 0.10000000149011612\n",
            "validate epoch:3\n",
            "Not using data augmentation.\n",
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3063 - accuracy: 0.1008 - val_loss: 2.3042 - val_accuracy: 0.1000\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3057 - accuracy: 0.0998 - val_loss: 2.3045 - val_accuracy: 0.1000\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3051 - accuracy: 0.1007 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Accuracy: 0.10000000149011612\n",
            "validate epoch:4\n",
            "Not using data augmentation.\n",
            "Epoch 1/4\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3049 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 2/4\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 2.2856 - accuracy: 0.1162 - val_loss: 2.1607 - val_accuracy: 0.1971\n",
            "Epoch 3/4\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.1093 - accuracy: 0.2191 - val_loss: 2.0231 - val_accuracy: 0.2626\n",
            "Epoch 4/4\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.0266 - accuracy: 0.2565 - val_loss: 1.9573 - val_accuracy: 0.2810\n",
            "Accuracy: 0.2809999883174896\n",
            "validate epoch:5\n",
            "Not using data augmentation.\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9838 - accuracy: 0.2707 - val_loss: 1.9342 - val_accuracy: 0.3058\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9532 - accuracy: 0.2848 - val_loss: 1.8910 - val_accuracy: 0.3170\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9307 - accuracy: 0.2944 - val_loss: 1.8650 - val_accuracy: 0.3198\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9082 - accuracy: 0.3017 - val_loss: 1.8419 - val_accuracy: 0.3329\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8915 - accuracy: 0.3100 - val_loss: 1.8298 - val_accuracy: 0.3412\n",
            "Accuracy: 0.34119999408721924\n",
            "validate epoch:6\n",
            "Not using data augmentation.\n",
            "Epoch 1/6\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8743 - accuracy: 0.3191 - val_loss: 1.8057 - val_accuracy: 0.3507\n",
            "Epoch 2/6\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8574 - accuracy: 0.3241 - val_loss: 1.7886 - val_accuracy: 0.3622\n",
            "Epoch 3/6\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8464 - accuracy: 0.3287 - val_loss: 1.7763 - val_accuracy: 0.3635\n",
            "Epoch 4/6\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8334 - accuracy: 0.3336 - val_loss: 1.7504 - val_accuracy: 0.3683\n",
            "Epoch 5/6\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8186 - accuracy: 0.3404 - val_loss: 1.7399 - val_accuracy: 0.3722\n",
            "Epoch 6/6\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8058 - accuracy: 0.3472 - val_loss: 1.7289 - val_accuracy: 0.3772\n",
            "Accuracy: 0.37720000743865967\n",
            "validate epoch:7\n",
            "Not using data augmentation.\n",
            "Epoch 1/7\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7900 - accuracy: 0.3541 - val_loss: 1.7185 - val_accuracy: 0.3837\n",
            "Epoch 2/7\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7721 - accuracy: 0.3562 - val_loss: 1.6829 - val_accuracy: 0.3909\n",
            "Epoch 3/7\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7541 - accuracy: 0.3663 - val_loss: 1.6625 - val_accuracy: 0.4016\n",
            "Epoch 4/7\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7358 - accuracy: 0.3713 - val_loss: 1.6475 - val_accuracy: 0.4106\n",
            "Epoch 5/7\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7192 - accuracy: 0.3798 - val_loss: 1.6455 - val_accuracy: 0.4047\n",
            "Epoch 6/7\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.7036 - accuracy: 0.3866 - val_loss: 1.6114 - val_accuracy: 0.4228\n",
            "Epoch 7/7\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6894 - accuracy: 0.3895 - val_loss: 1.6022 - val_accuracy: 0.4271\n",
            "Accuracy: 0.4271000027656555\n",
            "validate epoch:8\n",
            "Not using data augmentation.\n",
            "Epoch 1/8\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6719 - accuracy: 0.3983 - val_loss: 1.5846 - val_accuracy: 0.4270\n",
            "Epoch 2/8\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6590 - accuracy: 0.4061 - val_loss: 1.5725 - val_accuracy: 0.4326\n",
            "Epoch 3/8\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6492 - accuracy: 0.4081 - val_loss: 1.5784 - val_accuracy: 0.4355\n",
            "Epoch 4/8\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6353 - accuracy: 0.4144 - val_loss: 1.5563 - val_accuracy: 0.4398\n",
            "Epoch 5/8\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6253 - accuracy: 0.4182 - val_loss: 1.5343 - val_accuracy: 0.4494\n",
            "Epoch 6/8\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6108 - accuracy: 0.4242 - val_loss: 1.5295 - val_accuracy: 0.4479\n",
            "Epoch 7/8\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5969 - accuracy: 0.4270 - val_loss: 1.5250 - val_accuracy: 0.4533\n",
            "Epoch 8/8\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5840 - accuracy: 0.4347 - val_loss: 1.5242 - val_accuracy: 0.4514\n",
            "Accuracy: 0.4514000117778778\n",
            "validate epoch:9\n",
            "Not using data augmentation.\n",
            "Epoch 1/9\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5759 - accuracy: 0.4366 - val_loss: 1.5040 - val_accuracy: 0.4614\n",
            "Epoch 2/9\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5618 - accuracy: 0.4402 - val_loss: 1.4860 - val_accuracy: 0.4673\n",
            "Epoch 3/9\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5511 - accuracy: 0.4481 - val_loss: 1.4646 - val_accuracy: 0.4759\n",
            "Epoch 4/9\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5389 - accuracy: 0.4513 - val_loss: 1.4728 - val_accuracy: 0.4688\n",
            "Epoch 5/9\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5277 - accuracy: 0.4544 - val_loss: 1.4386 - val_accuracy: 0.4774\n",
            "Epoch 6/9\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5207 - accuracy: 0.4576 - val_loss: 1.4831 - val_accuracy: 0.4687\n",
            "Epoch 7/9\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5070 - accuracy: 0.4643 - val_loss: 1.4195 - val_accuracy: 0.4899\n",
            "Epoch 8/9\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4996 - accuracy: 0.4634 - val_loss: 1.4109 - val_accuracy: 0.4908\n",
            "Epoch 9/9\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4892 - accuracy: 0.4691 - val_loss: 1.3950 - val_accuracy: 0.4953\n",
            "Accuracy: 0.4952999949455261\n",
            "validate epoch:10\n",
            "Not using data augmentation.\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4784 - accuracy: 0.4732 - val_loss: 1.4229 - val_accuracy: 0.4892\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4711 - accuracy: 0.4751 - val_loss: 1.4117 - val_accuracy: 0.4935\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4634 - accuracy: 0.4802 - val_loss: 1.3961 - val_accuracy: 0.5010\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4548 - accuracy: 0.4816 - val_loss: 1.3856 - val_accuracy: 0.5001\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4478 - accuracy: 0.4836 - val_loss: 1.3621 - val_accuracy: 0.5092\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4359 - accuracy: 0.4880 - val_loss: 1.3708 - val_accuracy: 0.5075\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4335 - accuracy: 0.4891 - val_loss: 1.3524 - val_accuracy: 0.5160\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4260 - accuracy: 0.4917 - val_loss: 1.3345 - val_accuracy: 0.5187\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4147 - accuracy: 0.4980 - val_loss: 1.3462 - val_accuracy: 0.5150\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4085 - accuracy: 0.4988 - val_loss: 1.3303 - val_accuracy: 0.5189\n",
            "Accuracy: 0.5188999772071838\n",
            "act_performance_dict {'relu': [0.43290001153945923, 0.5544999837875366, 0.628000020980835, 0.6825000047683716, 0.7325000166893005, 0.7576000094413757, 0.7588000297546387, 0.7706999778747559, 0.7803999781608582, 0.7750999927520752]}\n",
            "temp_performance [0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.2809999883174896, 0.34119999408721924, 0.37720000743865967, 0.4271000027656555, 0.4514000117778778, 0.4952999949455261, 0.5188999772071838]\n",
            "{'relu': [0.43290001153945923, 0.5544999837875366, 0.628000020980835, 0.6825000047683716, 0.7325000166893005, 0.7576000094413757, 0.7588000297546387, 0.7706999778747559, 0.7803999781608582, 0.7750999927520752], 'sigmoid': [0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.2809999883174896, 0.34119999408721924, 0.37720000743865967, 0.4271000027656555, 0.4514000117778778, 0.4952999949455261, 0.5188999772071838]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrsNEh1yw_fX"
      },
      "source": [
        "To avoid repetitive training, I recorded one result from previous training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNIntC9ew8Ha"
      },
      "source": [
        "act_performance_dict={'relu': [0.4465000033378601, 0.5627999901771545, 0.6442999839782715, 0.6797000169754028, 0.7312999963760376, 0.7508000135421753, 0.7731999754905701, 0.7756999731063843, 0.7692999839782715, 0.7840999960899353], 'sigmoid': [0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.2971999943256378, 0.3671000003814697, 0.4027999937534332, 0.4535999894142151, 0.4912000000476837, 0.5238000154495239, 0.5351999998092651]}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O2f1EDeXDRW",
        "outputId": "f4e0cb4c-5c5e-4557-8576-937e0a83f5d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "df = pd.DataFrame(act_performance_dict)\n",
        "fig = df.plot()\n",
        "fig = fig.get_figure()\n",
        "fig.savefig('Q2.pdf')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU1Ud3tJxHWw",
        "outputId": "9cd92733-e80c-4796-893f-334d90b0b5a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "act_performance_dict"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'relu': [0.43290001153945923,\n",
              "  0.5544999837875366,\n",
              "  0.628000020980835,\n",
              "  0.6825000047683716,\n",
              "  0.7325000166893005,\n",
              "  0.7576000094413757,\n",
              "  0.7588000297546387,\n",
              "  0.7706999778747559,\n",
              "  0.7803999781608582,\n",
              "  0.7750999927520752],\n",
              " 'sigmoid': [0.10000000149011612,\n",
              "  0.10000000149011612,\n",
              "  0.10000000149011612,\n",
              "  0.2809999883174896,\n",
              "  0.34119999408721924,\n",
              "  0.37720000743865967,\n",
              "  0.4271000027656555,\n",
              "  0.4514000117778778,\n",
              "  0.4952999949455261,\n",
              "  0.5188999772071838]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYMy9TeE2H0t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55svRYLQuLdF"
      },
      "source": [
        "<h1> why did some models perform better or worse than\n",
        "other models and are the results consistent with the theory?</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bgnBKlD2_86"
      },
      "source": [
        "\n",
        "*   The biggest advantage of ReLu is indeed non-saturation of its gradient, which makes the model with ReLU performs bettern than sigmoid.\n",
        "*   Moreover, the model with ReLU is less expensive in computation resource.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGoOUEcU3dio"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}